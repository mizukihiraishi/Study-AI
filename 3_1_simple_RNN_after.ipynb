{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "3_1_simple_RNN_after.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ca49fd-a66d-4daa-ce3b-886d0f95acdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DNN_code')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzGmsHRwO-bi"
      },
      "source": [
        "# simple RNN after\n",
        "### バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KNSG0aKXO-bk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ceebb310-f2e9-451b-93aa-b0692543b98a"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.4313440772146624\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "104 + 75 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.8281931006587562\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "117 + 54 = 186\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0110359671894065\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "43 + 20 = 28\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9245262801110617\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "114 + 36 = 144\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.1037544041302612\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "122 + 47 = 245\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9551234301872317\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "53 + 102 = 254\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9235655474408366\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "33 + 53 = 83\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.140396616284116\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "111 + 65 = 238\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.8632123592802119\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "106 + 34 = 76\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.199376037459922\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "79 + 86 = 255\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0638657980162058\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "122 + 7 = 93\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9340359143097072\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "124 + 66 = 184\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.3477161911528939\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "95 + 53 = 255\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.1622685036543614\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "9 + 55 = 126\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.6244837290184003\n",
            "Pred:[0 0 0 1 0 1 1 0]\n",
            "True:[0 0 0 1 0 1 1 1]\n",
            "23 + 0 = 22\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8785455545982332\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "30 + 58 = 100\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8391772825832243\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "59 + 67 = 252\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.569583209159121\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "104 + 1 = 107\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.7131692108917373\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "81 + 47 = 255\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9137845373230711\n",
            "Pred:[1 1 0 0 0 1 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "113 + 87 = 196\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.5661472869218107\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "0 + 89 = 81\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.6929226661533955\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "122 + 2 = 56\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.5061538914842174\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "69 + 105 = 174\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.604867094285692\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "85 + 82 = 167\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.6031362402244116\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "51 + 87 = 136\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.20654131140085646\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "42 + 16 = 58\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.3178714220021411\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "3 + 36 = 39\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.5924878397165322\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "50 + 89 = 203\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.40142686489105767\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "105 + 82 = 251\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.0408611094363545\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "7 + 88 = 99\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.19458940363695085\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "72 + 89 = 161\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.21834826595627294\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "90 + 18 = 108\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.11290626306453802\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "56 + 26 = 82\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.08436094364449989\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "2 + 70 = 72\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.08631383027340907\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "74 + 101 = 175\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.03779045861260585\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "98 + 4 = 102\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.10976809478667107\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "102 + 123 = 225\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.07435056543206689\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "113 + 71 = 184\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.03884846993423743\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "30 + 20 = 50\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.053719835566075264\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "46 + 51 = 97\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.0331337414936901\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "42 + 25 = 67\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.017741987535339187\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "98 + 28 = 126\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.03671007109752531\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "73 + 22 = 95\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.022933787660942756\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "88 + 29 = 117\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.011147874737836452\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "0 + 85 = 85\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.0301350931155146\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "56 + 119 = 175\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.05381164894678595\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "59 + 10 = 69\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.049507623752622694\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "43 + 106 = 149\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.024837955200349402\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "77 + 94 = 171\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.012015378942857079\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "97 + 0 = 97\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.014132130127174921\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "12 + 74 = 86\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.03036144348476048\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "11 + 110 = 121\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.013187812409826416\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "119 + 19 = 138\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.01561176241378629\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "96 + 127 = 223\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.0050895798753509474\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "105 + 7 = 112\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.009058276017704585\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "59 + 27 = 86\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.011768495948679939\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "45 + 60 = 105\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.00468822572895112\n",
            "Pred:[1 0 1 1 0 0 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "84 + 93 = 177\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.005822990692141266\n",
            "Pred:[1 0 1 1 0 0 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "66 + 111 = 177\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.009208674311483422\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "85 + 110 = 195\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.004121782782668461\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "87 + 27 = 114\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.0044191119252380345\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "104 + 15 = 119\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.006493128423490676\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "68 + 119 = 187\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.005189662885375101\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "66 + 2 = 68\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.00567010307742872\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "1 + 100 = 101\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.007419630340131294\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "120 + 14 = 134\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.006819442544212829\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "80 + 124 = 204\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.005355349664777774\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "32 + 100 = 132\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.003906662889042608\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "38 + 80 = 118\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.004407617271434645\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "77 + 52 = 129\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0070578644000440695\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "10 + 84 = 94\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.007957213891668877\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "43 + 110 = 153\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.0031153756938340446\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "25 + 74 = 99\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.002378762617437365\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "35 + 103 = 138\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0029723245880652737\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "127 + 71 = 198\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0037909679674635096\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "121 + 84 = 205\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.00276788327078008\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "82 + 40 = 122\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0015529161820612687\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "84 + 3 = 87\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.0019789040057473658\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "20 + 115 = 135\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.0035742530365160756\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "122 + 70 = 192\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0013911174283514505\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 0 0 0 1 1 0 1]\n",
            "6 + 7 = 13\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0026353581336051846\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "52 + 4 = 56\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.001676949391116399\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "23 + 83 = 106\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0030514778172781474\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "26 + 116 = 142\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0018499234187270602\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "98 + 47 = 145\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0027387663809250286\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "0 + 44 = 44\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0009108354845076286\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "47 + 67 = 114\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.002382422416019539\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "36 + 28 = 64\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0025875418214813734\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "24 + 86 = 110\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0011244821412212526\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "40 + 117 = 157\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0007708694589446415\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "19 + 53 = 72\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0010523330167723213\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "74 + 3 = 77\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0012177615251714867\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "30 + 71 = 101\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.001146593733404003\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "85 + 79 = 164\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0010556232624947099\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "91 + 79 = 170\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0004656338945953349\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "71 + 49 = 120\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0030003595397829507\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 0 0 1 0 1 0 1]\n",
            "19 + 2 = 21\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0011684425225267664\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "114 + 93 = 207\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0003548572971120515\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "15 + 65 = 80\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.001352400561843321\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "14 + 64 = 78\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsBt7vxmO-bn"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
        "weight_init_stdを変更する\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1.5\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0y3QgiRULZ5o",
        "outputId": "63911f09-f90e-4197-f77e-87cd7f1cf0a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.511213217091532\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "95 + 115 = 254\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.2265845090733776\n",
            "Pred:[0 0 0 0 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "94 + 120 = 7\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.130502590572327\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "52 + 12 = 17\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0628759360060847\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "57 + 55 = 74\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.2975863299631967\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "99 + 12 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9216308035436299\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "60 + 71 = 15\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.8912755321825148\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "19 + 74 = 84\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0489489129166123\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "1 + 72 = 212\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.8541161023103092\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "49 + 119 = 138\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.7540428971988976\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "75 + 11 = 6\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.745344203755376\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "3 + 71 = 78\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.1635263083235565\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "9 + 23 = 26\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.999238442897726\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "35 + 69 = 70\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.7872535580640915\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "64 + 12 = 28\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0936565379868624\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "101 + 35 = 66\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8900316688798461\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "91 + 69 = 134\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.7717481360100101\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "79 + 86 = 169\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.6424347431147077\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "12 + 116 = 152\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.2212053116999033\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "7 + 119 = 24\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.6229794979700366\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "74 + 27 = 117\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8560038946161603\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "23 + 91 = 110\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.43143728202484843\n",
            "Pred:[0 0 0 1 1 1 1 0]\n",
            "True:[0 0 0 1 1 1 1 0]\n",
            "17 + 13 = 30\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.6092253248208597\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "118 + 89 = 255\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.6347618241957987\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "106 + 25 = 35\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.45931163745938536\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "96 + 75 = 139\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.46449315245183476\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "47 + 43 = 86\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.28060438452652764\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "7 + 34 = 45\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.5502931428056179\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "59 + 39 = 74\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.10656998092408441\n",
            "Pred:[1 1 1 0 1 1 0 1]\n",
            "True:[1 1 1 0 1 1 0 1]\n",
            "114 + 123 = 237\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.24325218763283973\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "24 + 57 = 81\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.4497643150236149\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "103 + 125 = 230\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.3183939160324703\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "13 + 43 = 56\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.15055839132673676\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 1 0 1 1 0 1 1]\n",
            "122 + 97 = 219\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.2769860167205862\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "77 + 68 = 153\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.023219436890943048\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "16 + 29 = 45\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.2560968078318318\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "60 + 59 = 115\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.09697697996236433\n",
            "Pred:[0 0 0 1 0 1 1 0]\n",
            "True:[0 0 0 1 0 1 1 0]\n",
            "7 + 15 = 22\n",
            "------------\n",
            "iters:3700\n",
            "Loss:1.079705698061129\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "87 + 105 = 186\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.04425526173992526\n",
            "Pred:[0 0 0 1 1 1 1 0]\n",
            "True:[0 0 0 1 1 1 1 0]\n",
            "13 + 17 = 30\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.01260445365285874\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "32 + 112 = 144\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.06956100036761918\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "104 + 42 = 146\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.04560099328427946\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "82 + 76 = 158\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.008440286599083953\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 0 0 0 1 1 1 0]\n",
            "4 + 10 = 14\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.17583421722212178\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "103 + 39 = 142\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.009273071966250046\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "66 + 86 = 152\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.007211390835264557\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "104 + 77 = 181\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.03206288460125345\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "124 + 13 = 137\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.07768625985971955\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "123 + 13 = 136\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.011093935677899586\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "33 + 90 = 123\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.013497778120093475\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "124 + 39 = 163\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.03898887859738252\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "127 + 43 = 170\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.04155425419898995\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "96 + 108 = 204\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.006960545982258476\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "53 + 62 = 115\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.05195490538317116\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "21 + 102 = 123\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.005223766633011447\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "40 + 53 = 93\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.0035103697175613833\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "66 + 5 = 71\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.0035161703757202478\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "69 + 123 = 192\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.003559223462116308\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "36 + 100 = 136\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.002239244413717968\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "8 + 20 = 28\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.0040169815199656\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "38 + 67 = 105\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.003548143795187534\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "60 + 109 = 169\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.005084913695892206\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "50 + 80 = 130\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.003954284234462343\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "92 + 29 = 121\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.002774603467011448\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "106 + 124 = 230\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.003420411072172601\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "62 + 27 = 89\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.0025344818037798937\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "112 + 47 = 159\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.0021116045923183584\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "20 + 42 = 62\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0019962155251884474\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "17 + 78 = 95\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.002329940737787605\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "72 + 50 = 122\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.004503603485155135\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "63 + 99 = 162\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.004363599646992131\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "124 + 99 = 223\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.004046316619959524\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "19 + 81 = 100\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.0015064219489392956\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "90 + 93 = 183\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.0018162288910228458\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "112 + 118 = 230\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0020314059138930923\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "88 + 6 = 94\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0010099568701439077\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "4 + 37 = 41\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.0030136030894134225\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "109 + 4 = 113\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0016262601138568745\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "122 + 37 = 159\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003437159540549861\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "39 + 104 = 143\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.003475114726595838\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "19 + 44 = 63\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.001286140509633325\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "121 + 68 = 189\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0015988349514134165\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "89 + 78 = 167\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.0011090019014155627\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "72 + 99 = 171\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0020174825265681347\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "35 + 77 = 112\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0008064419278900455\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "18 + 125 = 143\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0010918717376099066\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "89 + 16 = 105\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0011529428062880963\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 0 0 0 1 1 1 0]\n",
            "0 + 14 = 14\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0011750697785765933\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "16 + 104 = 120\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00022860451354024623\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "41 + 1 = 42\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0006698163977003662\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "26 + 89 = 115\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0033547695120093503\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "127 + 33 = 160\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0009933572757382873\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "67 + 53 = 120\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.001764022134391278\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "115 + 18 = 133\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0009537538571305995\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "64 + 62 = 126\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0015060666225353524\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "62 + 8 = 70\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0007890686432369469\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "99 + 17 = 116\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0011396604114995244\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "24 + 82 = 106\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0008103466987310861\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "2 + 74 = 76\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0013632682728765679\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "39 + 73 = 112\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0006383510872828758\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "60 + 81 = 141\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "learning_rateを変更\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "w3Qmq3L5Mgm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.5\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cYbHZMsuMqLC",
        "outputId": "ef585e84-8f31-49b5-da87-4c0529691155"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.1269435558863026\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "87 + 92 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.2603082029210686\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 1 0 0]\n",
            "112 + 108 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.03212737698418\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "59 + 93 = 178\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.148482043909261\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "91 + 3 = 1\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9321313259922605\n",
            "Pred:[1 1 1 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "112 + 34 = 242\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9021923790583171\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "16 + 45 = 127\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.8184913393676977\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "94 + 90 = 180\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.7547145178932528\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "100 + 10 = 118\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.7439788431294585\n",
            "Pred:[1 1 1 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "53 + 84 = 235\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.2689705820155969\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "7 + 55 = 62\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9493875792158254\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "43 + 113 = 172\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.07405401262140682\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "93 + 117 = 210\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.015073036870924268\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "12 + 79 = 91\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.007291059522613251\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "5 + 105 = 110\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.012866183080503045\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "102 + 52 = 154\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.049338482603996446\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "81 + 47 = 128\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.010148652635913349\n",
            "Pred:[0 0 1 1 1 1 0 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "18 + 43 = 61\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.003114377326088086\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "112 + 5 = 117\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.003075755271068909\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "74 + 60 = 134\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.0038971929586533844\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "20 + 74 = 94\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.0016799132680576135\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "19 + 9 = 28\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.0014066327546417745\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "70 + 46 = 116\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.0033351015518703906\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "43 + 64 = 107\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.0007541799623482932\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "34 + 37 = 71\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.0007103817319903727\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "106 + 49 = 155\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.0008617201916979618\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "74 + 113 = 187\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.00012627388242427367\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "25 + 53 = 78\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.0007463970814619057\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "24 + 95 = 119\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.0006735686185246638\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "41 + 82 = 123\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.0005534009970467484\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "19 + 86 = 105\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.0004198515664412517\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "66 + 91 = 157\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.0004117104363351033\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "87 + 63 = 150\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.000468433402799797\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "78 + 103 = 181\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.00020928895902861937\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "83 + 79 = 162\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.0005080000382539112\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "110 + 124 = 234\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.0005422869013478241\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "46 + 62 = 108\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.0002476498842272662\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "84 + 49 = 133\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.00023673356632062945\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 1 0 1 0 0 1 1]\n",
            "106 + 105 = 211\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.00016416933049088158\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "31 + 87 = 118\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.0003438887133176416\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "97 + 88 = 185\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.0005517809978069338\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "23 + 4 = 27\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.00029560312955180794\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "66 + 44 = 110\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.0001532743779681096\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "77 + 87 = 164\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.00019254824034496953\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "82 + 75 = 157\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.000300143523590994\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "86 + 30 = 116\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.00023701248634521062\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "49 + 80 = 129\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.00022150623917473232\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "12 + 34 = 46\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.0002675702533488893\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "63 + 65 = 128\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.00011807521317284358\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "47 + 101 = 148\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.0002094835394703474\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "124 + 13 = 137\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.00026438620449242405\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "120 + 28 = 148\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.00010771144577092569\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "48 + 53 = 101\n",
            "------------\n",
            "iters:5200\n",
            "Loss:6.53152027055769e-05\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "115 + 51 = 166\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.00010848025351140714\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "64 + 79 = 143\n",
            "------------\n",
            "iters:5400\n",
            "Loss:8.377676837356171e-05\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "78 + 37 = 115\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.0001899647285128622\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "24 + 74 = 98\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.00012665407525043693\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "37 + 74 = 111\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.00018343437588998733\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "117 + 36 = 153\n",
            "------------\n",
            "iters:5800\n",
            "Loss:6.790506661014932e-05\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "42 + 81 = 123\n",
            "------------\n",
            "iters:5900\n",
            "Loss:6.512465229680892e-05\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "18 + 105 = 123\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.00012152386573182879\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "113 + 112 = 225\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.00012660465124890696\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "22 + 60 = 82\n",
            "------------\n",
            "iters:6200\n",
            "Loss:1.9395976619862173e-05\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "53 + 39 = 92\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.00011920422855858096\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "28 + 74 = 102\n",
            "------------\n",
            "iters:6400\n",
            "Loss:5.277575127229874e-05\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "26 + 9 = 35\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.00010516386889922103\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "109 + 50 = 159\n",
            "------------\n",
            "iters:6600\n",
            "Loss:1.6570160674293713e-05\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "117 + 33 = 150\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.00010462384652309125\n",
            "Pred:[1 1 0 1 0 1 0 1]\n",
            "True:[1 1 0 1 0 1 0 1]\n",
            "121 + 92 = 213\n",
            "------------\n",
            "iters:6800\n",
            "Loss:7.547110317654243e-05\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "59 + 116 = 175\n",
            "------------\n",
            "iters:6900\n",
            "Loss:2.3499495032596878e-05\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "83 + 103 = 186\n",
            "------------\n",
            "iters:7000\n",
            "Loss:4.538721626202869e-05\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "2 + 41 = 43\n",
            "------------\n",
            "iters:7100\n",
            "Loss:9.3577504731806e-05\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "125 + 46 = 171\n",
            "------------\n",
            "iters:7200\n",
            "Loss:1.568609383506815e-05\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 0 0 1 0 1 0 0]\n",
            "13 + 7 = 20\n",
            "------------\n",
            "iters:7300\n",
            "Loss:7.879198158394145e-05\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "81 + 70 = 151\n",
            "------------\n",
            "iters:7400\n",
            "Loss:3.5785167188557205e-05\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "31 + 11 = 42\n",
            "------------\n",
            "iters:7500\n",
            "Loss:1.1876924477996928e-05\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "85 + 79 = 164\n",
            "------------\n",
            "iters:7600\n",
            "Loss:4.174792683448652e-05\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "66 + 43 = 109\n",
            "------------\n",
            "iters:7700\n",
            "Loss:6.915321884604158e-05\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "39 + 60 = 99\n",
            "------------\n",
            "iters:7800\n",
            "Loss:5.731143500743757e-05\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "39 + 88 = 127\n",
            "------------\n",
            "iters:7900\n",
            "Loss:3.762196808859745e-05\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "98 + 39 = 137\n",
            "------------\n",
            "iters:8000\n",
            "Loss:5.736020164905418e-05\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "69 + 22 = 91\n",
            "------------\n",
            "iters:8100\n",
            "Loss:5.955138747856981e-05\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "37 + 110 = 147\n",
            "------------\n",
            "iters:8200\n",
            "Loss:1.9693258076691937e-05\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "119 + 35 = 154\n",
            "------------\n",
            "iters:8300\n",
            "Loss:7.387175210077135e-06\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "113 + 67 = 180\n",
            "------------\n",
            "iters:8400\n",
            "Loss:1.3484211456876213e-05\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "35 + 15 = 50\n",
            "------------\n",
            "iters:8500\n",
            "Loss:3.7753772387102e-05\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "96 + 27 = 123\n",
            "------------\n",
            "iters:8600\n",
            "Loss:2.9084166549164157e-05\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "63 + 29 = 92\n",
            "------------\n",
            "iters:8700\n",
            "Loss:4.4286257102819716e-05\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "112 + 25 = 137\n",
            "------------\n",
            "iters:8800\n",
            "Loss:5.839950046564007e-05\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "110 + 116 = 226\n",
            "------------\n",
            "iters:8900\n",
            "Loss:5.0608618485815455e-06\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "37 + 71 = 108\n",
            "------------\n",
            "iters:9000\n",
            "Loss:3.076959327189099e-05\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "48 + 11 = 59\n",
            "------------\n",
            "iters:9100\n",
            "Loss:4.0514172719750895e-05\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "20 + 39 = 59\n",
            "------------\n",
            "iters:9200\n",
            "Loss:3.081984248271142e-05\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "44 + 115 = 159\n",
            "------------\n",
            "iters:9300\n",
            "Loss:5.428626662784851e-05\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "76 + 78 = 154\n",
            "------------\n",
            "iters:9400\n",
            "Loss:5.2925853084767804e-05\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "115 + 60 = 175\n",
            "------------\n",
            "iters:9500\n",
            "Loss:2.451336647639733e-05\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "95 + 17 = 112\n",
            "------------\n",
            "iters:9600\n",
            "Loss:3.971528884416802e-05\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "59 + 8 = 67\n",
            "------------\n",
            "iters:9700\n",
            "Loss:3.258009797066868e-05\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "84 + 39 = 123\n",
            "------------\n",
            "iters:9800\n",
            "Loss:3.402958902123565e-05\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "84 + 111 = 195\n",
            "------------\n",
            "iters:9900\n",
            "Loss:7.745368028979958e-05\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "92 + 46 = 138\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "hidden_layer_sizeを変更\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "FByvPqt-Mk6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 64\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kySu-k0yMrnJ",
        "outputId": "fc90d9fd-1718-4e7b-d805-a6e74180b222"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.9421954110608528\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "81 + 60 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.030564757681213\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "109 + 23 = 1\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9461657582141463\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "126 + 41 = 255\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.1056633381630858\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "44 + 126 = 253\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9402289369582209\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "74 + 78 = 28\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9019030781620507\n",
            "Pred:[0 0 0 1 0 0 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "27 + 76 = 19\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.1582340808023772\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "88 + 60 = 254\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.841673927374931\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "67 + 18 = 3\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.8913808888518179\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "71 + 64 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8674475492760101\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "116 + 7 = 255\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.1878929730344512\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "71 + 40 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.1494994341124969\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "25 + 41 = 121\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.9636432780633967\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "110 + 74 = 144\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8164446242667645\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "97 + 99 = 141\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.55426153650505\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "2 + 81 = 83\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.9524183307903105\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "48 + 101 = 128\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.9667093353538267\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "80 + 7 = 0\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.8295971006734074\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "22 + 103 = 255\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.8675708141996746\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "21 + 60 = 105\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.4906361638126263\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "33 + 26 = 63\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.080129293461205\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "31 + 69 = 0\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.8964190714221456\n",
            "Pred:[0 0 0 1 0 0 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "3 + 60 = 19\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.5362345164718155\n",
            "Pred:[0 0 0 1 1 1 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "14 + 12 = 30\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.9373349286660971\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "45 + 98 = 111\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.1155586874229046\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "71 + 123 = 172\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.8560428030640621\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "92 + 29 = 127\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.8580530554042558\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "20 + 63 = 107\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.7898319020777084\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "56 + 22 = 126\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.48962987398239194\n",
            "Pred:[0 0 1 1 1 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "29 + 24 = 61\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.7192863076150544\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "117 + 33 = 212\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.5699149327260614\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "83 + 30 = 113\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.1787825519391868\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "111 + 46 = 1\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.8196412087395603\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "109 + 121 = 132\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.5139746030096981\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "82 + 79 = 225\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.5825091829085698\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "56 + 43 = 71\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.7816934538296647\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "61 + 93 = 128\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.4740765813128263\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "47 + 63 = 126\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.2607588619874023\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "91 + 12 = 103\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.2552432335224355\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "105 + 118 = 223\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.2652089871342662\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "10 + 76 = 86\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.24088037624360664\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "121 + 23 = 144\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.549025280677237\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "70 + 93 = 179\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.2016518120617235\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "121 + 87 = 208\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.5653840005436305\n",
            "Pred:[1 1 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "119 + 23 = 206\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.18004187998791607\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "26 + 27 = 53\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.21631961237093708\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "38 + 92 = 130\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.16197799226918255\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "73 + 9 = 80\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.09548468178148664\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "1 + 127 = 128\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.0658101174327979\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "9 + 104 = 113\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.15560224763324335\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "39 + 35 = 74\n",
            "------------\n",
            "iters:5000\n",
            "Loss:1.687167364728972\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "27 + 114 = 125\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.6754441549343249\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "15 + 36 = 39\n",
            "------------\n",
            "iters:5200\n",
            "Loss:1.1334569433458144\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "89 + 36 = 141\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.35706018885212565\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "19 + 31 = 34\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.6155600768107776\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "110 + 58 = 128\n",
            "------------\n",
            "iters:5500\n",
            "Loss:1.6875165540722865\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "69 + 27 = 92\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.14399222371212167\n",
            "Pred:[1 1 1 0 1 0 0 1]\n",
            "True:[1 1 1 0 1 0 0 1]\n",
            "108 + 125 = 233\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.15024195081617656\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "65 + 99 = 164\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.39404293467073315\n",
            "Pred:[1 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "21 + 91 = 240\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.16665090803255933\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "94 + 18 = 112\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.49971186773766835\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "28 + 35 = 47\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.22845504241387288\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "15 + 57 = 72\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.1366800356639158\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "35 + 127 = 162\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.03794855094604202\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "118 + 90 = 208\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.057216358291951305\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "88 + 20 = 108\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.08756473391363034\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "110 + 18 = 128\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.040170463988307654\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "66 + 49 = 115\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.024308756560200484\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "5 + 110 = 115\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.7991189122526685\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "94 + 27 = 225\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.012630032356913259\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "22 + 104 = 126\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.08976950105849138\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "53 + 109 = 162\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.01015967120979832\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "88 + 13 = 101\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.01814022709211897\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "30 + 120 = 150\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.01509994720372414\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "78 + 101 = 179\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.018813475849657667\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "40 + 24 = 64\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0050960433427549145\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "9 + 46 = 55\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.0035267169351336325\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "33 + 70 = 103\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0029101510630660326\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "45 + 4 = 49\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.0019747679242829905\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "28 + 98 = 126\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.010717152712800417\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "22 + 110 = 132\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.008639715227453935\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "10 + 35 = 45\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.010773660578691833\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "17 + 9 = 26\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.017299342329884733\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "14 + 43 = 57\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.005901658433939024\n",
            "Pred:[1 1 0 1 1 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "123 + 93 = 216\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0050989457579159285\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "15 + 85 = 100\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.002157496675288293\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "28 + 77 = 105\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0030751599796305026\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "118 + 43 = 161\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.010249998789709345\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "105 + 69 = 174\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0019094957548581944\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "71 + 82 = 153\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.001959951965338421\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "60 + 6 = 66\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0038796275136052556\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 0 0 0 1 0]\n",
            "14 + 20 = 34\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0014704649565726073\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "83 + 106 = 189\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0016863095377383525\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "62 + 48 = 110\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0055003802031831275\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "24 + 92 = 116\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0014763960056716988\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "120 + 13 = 133\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0011418612064427814\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "2 + 104 = 106\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0015306090009168957\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 0 0 0 1 0]\n",
            "24 + 10 = 34\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.001886964892779383\n",
            "Pred:[1 1 1 1 1 0 0 0]\n",
            "True:[1 1 1 1 1 0 0 0]\n",
            "127 + 121 = 248\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0018339427525778332\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "41 + 55 = 96\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.001348282542269387\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "33 + 96 = 129\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] 重みの初期化方法を変更してみよう\n",
        "Xavier\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "pd8Bba4aLfkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "# W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "# W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "# W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uCy_NmkGLjnh",
        "outputId": "f58a4c82-e694-4ced-928a-bbac8a8ccd63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:0.9696136724686222\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "7 + 35 = 160\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.8956085359639231\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "126 + 95 = 255\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9687606765135957\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "56 + 19 = 2\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0542947001592886\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "73 + 21 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9286583152050156\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "21 + 26 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0513705446459787\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "40 + 121 = 255\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.928174624881729\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "88 + 58 = 0\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9943114684563512\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "107 + 21 = 2\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9596602856709657\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "49 + 68 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9463416984155499\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "99 + 68 = 231\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0479820841403997\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "16 + 17 = 255\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9830396022961749\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "68 + 41 = 254\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0099088920423398\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "17 + 124 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0662129056185106\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "48 + 91 = 255\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0208675848063054\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "126 + 24 = 254\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.9787409704336576\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "99 + 43 = 68\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0009585100129474\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "120 + 33 = 80\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9042756881473794\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "6 + 34 = 68\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9144970921945722\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "58 + 41 = 82\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.6872131076146307\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "16 + 32 = 96\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.048025130251378\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "62 + 19 = 45\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.880408498180419\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "70 + 3 = 141\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.86467578889275\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "39 + 5 = 15\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.9399538471645787\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "111 + 71 = 158\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.1845296652203876\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "109 + 56 = 211\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.8311376751494323\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "21 + 14 = 59\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.7609971252284189\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "82 + 32 = 64\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.8049418806449482\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "104 + 55 = 255\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.7004946322087061\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "99 + 122 = 133\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.6607625379408606\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "45 + 110 = 219\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.4880905027859556\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 0 0 1 0 0 1 1]\n",
            "19 + 0 = 3\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.6396681219737153\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "70 + 44 = 122\n",
            "------------\n",
            "iters:3200\n",
            "Loss:1.066923412008469\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "123 + 86 = 169\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.4889680762802291\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "75 + 48 = 123\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.24731414738873853\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "72 + 100 = 172\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.4493883999083081\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "49 + 96 = 147\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.5532647301144387\n",
            "Pred:[0 0 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "38 + 34 = 12\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.3700521722509381\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "8 + 51 = 59\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.3290431602473722\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "99 + 9 = 110\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.19956828300892443\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "16 + 112 = 128\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.18200763288136526\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "83 + 75 = 158\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.7897253492147105\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "44 + 119 = 155\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.2899290960808013\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "126 + 47 = 173\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.18496721558401663\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "81 + 20 = 101\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.22324546621081057\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "69 + 31 = 100\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.1707938102017549\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "54 + 2 = 56\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.3197893010969405\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "61 + 72 = 133\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.25627380088708646\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "126 + 105 = 231\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.39610887199334627\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "47 + 93 = 140\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.07966540446338827\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "120 + 65 = 185\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.08753177157807428\n",
            "Pred:[1 1 0 1 1 0 0 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "122 + 95 = 217\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.013829688225763432\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "25 + 17 = 42\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.10076143748508071\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "26 + 109 = 135\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.03981639835519476\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "13 + 80 = 93\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.1280097423603872\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "112 + 0 = 112\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.07401215127291233\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "26 + 90 = 116\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.03545497949002676\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "18 + 76 = 94\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.06436777799944819\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "111 + 90 = 201\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.021866103571837273\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "75 + 95 = 170\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.04305848368523762\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "2 + 34 = 36\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.057040733660929\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "3 + 108 = 111\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.0431708764167305\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "12 + 14 = 26\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.019726529324733948\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "29 + 95 = 124\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.02266065160162502\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "32 + 16 = 48\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.049182698049412485\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "111 + 56 = 167\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.021783612576822355\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "18 + 125 = 143\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.01714659430011511\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "92 + 57 = 149\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.02016393530781932\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "39 + 125 = 164\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.024067398966825887\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "34 + 90 = 124\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.010508220263044134\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "4 + 125 = 129\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.010496888659401004\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "39 + 34 = 73\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.010965879674113284\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "81 + 28 = 109\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.006161390278998515\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "3 + 49 = 52\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.0037342036260939646\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "9 + 95 = 104\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.016375891298264007\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "77 + 56 = 133\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.014024968932036764\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "20 + 102 = 122\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.01305047777555718\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "68 + 36 = 104\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.010928667496013015\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "88 + 70 = 158\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.016934284145169065\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "18 + 80 = 98\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.006854038867166628\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "116 + 5 = 121\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0031858403099296047\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "7 + 19 = 26\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.008229081599073738\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "59 + 38 = 97\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.0028720367400958896\n",
            "Pred:[1 1 1 1 0 1 0 0]\n",
            "True:[1 1 1 1 0 1 0 0]\n",
            "121 + 123 = 244\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.019962637232264605\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "14 + 114 = 128\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.009931015979435763\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "115 + 18 = 133\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0030018011688552606\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "105 + 53 = 158\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.001226937898375341\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "65 + 49 = 114\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.014393150729909104\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "55 + 8 = 63\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00925721137921335\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "111 + 40 = 151\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.005012769538582962\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "98 + 65 = 163\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.004019808484790383\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "67 + 54 = 121\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.004521434263317076\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "7 + 89 = 96\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0031222174556482076\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "45 + 119 = 164\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0034130992649747025\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "37 + 48 = 85\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0033315996739588746\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "39 + 49 = 88\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.00559608031967749\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "67 + 48 = 115\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.007191994038262611\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 1 1 1 0 1 1 1]\n",
            "121 + 126 = 247\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.005192992712836147\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "62 + 20 = 82\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0023478332161306244\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "127 + 75 = 202\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.003998558804051682\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "14 + 44 = 58\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "He\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "U0zdMVEKMNVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "# W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "# W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "# W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SMHPx1BuMVx-",
        "outputId": "1f0714e9-2e12-47ff-998e-ff9bc8f99b89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.0775959262665393\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "35 + 11 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9034266556416923\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "30 + 94 = 127\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9527975399298422\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "57 + 58 = 48\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0979885982381345\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "105 + 74 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.1794080039452697\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "112 + 32 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9516731455213796\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "98 + 114 = 197\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9504346971098173\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "21 + 114 = 173\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.106542698827801\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "53 + 111 = 255\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0118829006942123\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "117 + 18 = 101\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9278759734020471\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "101 + 23 = 239\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9421620510096597\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 1 1 1 0 0 0 0]\n",
            "124 + 116 = 136\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.0171042825539398\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "64 + 118 = 173\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.9701771565335549\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "36 + 75 = 223\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.1107322605755083\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "55 + 10 = 63\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.794104955732143\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "115 + 80 = 227\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8755752222122606\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "48 + 38 = 64\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8787549641208786\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "73 + 36 = 73\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0026916184539345\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "97 + 71 = 134\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.5184711721475559\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 0 0 0 1 0]\n",
            "2 + 0 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.7510342372125092\n",
            "Pred:[0 0 0 1 0 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "12 + 27 = 23\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.9863849527415273\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "93 + 3 = 10\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.0179304395685396\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "57 + 74 = 114\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.6051338113385258\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "110 + 124 = 250\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.6419200627887444\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "57 + 29 = 118\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.8923288636200979\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "118 + 91 = 180\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0561745069938986\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "126 + 2 = 120\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.460931033572067\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "88 + 17 = 105\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.4574340327504249\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "6 + 46 = 60\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.45472008387425855\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "68 + 37 = 41\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.2139550797512962\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "8 + 40 = 48\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6638481432133365\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "93 + 50 = 207\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.18095562864429313\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "75 + 83 = 158\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.25402112359253726\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "113 + 2 = 115\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.13881522403192698\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "8 + 29 = 37\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.2443667663051581\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "102 + 13 = 115\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.2084437817905023\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "17 + 71 = 92\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.15313304275730658\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "69 + 25 = 94\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.09067065422488657\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "48 + 24 = 72\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.02388891242915426\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "19 + 39 = 58\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.22992444058791917\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "50 + 125 = 175\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.056900422311237694\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "104 + 28 = 132\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.10946152763654858\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "52 + 59 = 111\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.02712039810679683\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "79 + 34 = 113\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.14135456293389811\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "90 + 53 = 143\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.055795203056389776\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "108 + 13 = 121\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.021279617044958715\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "5 + 95 = 100\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.028307053796489796\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "98 + 82 = 180\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.0949045296693305\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "56 + 71 = 127\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.011980343640042735\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "91 + 112 = 203\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.021563088853039168\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "122 + 16 = 138\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.02286878970332748\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "58 + 118 = 176\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.021929183859016717\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "28 + 10 = 38\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.019616044089226972\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "54 + 68 = 122\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.015262246608629241\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "108 + 2 = 110\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.0044445962767569805\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "121 + 101 = 222\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.005477749175558613\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "115 + 73 = 188\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.01604402674400178\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "48 + 71 = 119\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.005898275115272177\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "37 + 100 = 137\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.003210175951260853\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "125 + 33 = 158\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.009242682454186892\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "32 + 44 = 76\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.0030636131543040545\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "83 + 21 = 104\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.0022744533067309337\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "11 + 89 = 100\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.0016636333080712095\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "123 + 19 = 142\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.008927117823776243\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "18 + 93 = 111\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.007590244247977326\n",
            "Pred:[1 1 0 0 0 1 0 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "116 + 80 = 196\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.005562065014039043\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "42 + 123 = 165\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.002837196389984981\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "43 + 32 = 75\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0012379981155826014\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "121 + 105 = 226\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.00716373779636107\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "70 + 28 = 98\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.00543520844040755\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "104 + 49 = 153\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0019535002392175116\n",
            "Pred:[1 1 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "121 + 79 = 200\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0027864871234941357\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "119 + 60 = 179\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.002307543482637923\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "23 + 4 = 27\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.004685034123030309\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "86 + 30 = 116\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0007267504972514328\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "127 + 31 = 158\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0022897546611797665\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "39 + 2 = 41\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.0017980673360397771\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "43 + 6 = 49\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.003336585948123053\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "48 + 72 = 120\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003198800987343648\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "58 + 107 = 165\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.00265425750120482\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "38 + 79 = 117\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0017439309576429023\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "45 + 60 = 105\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0008206255196942357\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "37 + 109 = 146\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.0032805862206948203\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "56 + 74 = 130\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0013701340820615816\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "59 + 46 = 105\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.00044597584170723726\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "25 + 17 = 42\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.002913785972775945\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "118 + 90 = 208\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.000642989562356674\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "85 + 13 = 98\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.001246924456387871\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "17 + 127 = 144\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0011083564944134954\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "57 + 71 = 128\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0008831686633143503\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "13 + 16 = 29\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.002306677870048084\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "32 + 0 = 32\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0005766254711864828\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "63 + 99 = 162\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0020786877020082728\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "6 + 104 = 110\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0003388840852366221\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "71 + 7 = 78\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.002072962794714457\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "118 + 84 = 202\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.000719451121271437\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "19 + 8 = 27\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0010707256007586878\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "23 + 112 = 135\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0008733582844243896\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "109 + 92 = 201\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0017281103211259003\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "76 + 51 = 127\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0003272666868917479\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "99 + 33 = 132\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] 中間層の活性化関数を変更してみよう\n",
        "ReLU(勾配爆発を確認しよう)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "IgRCWH-eLjOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        # z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "        z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        # delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])  \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_relu(y[:,t])     \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        # delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iV4GHmBBMtJU",
        "outputId": "0626d036-d6a7-4953-de30-05bdb06d8ab0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/DNN_code/common/functions.py:6: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:2.5030286979229333\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "73 + 116 = 91\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "107 + 50 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "98 + 124 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "6 + 18 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "72 + 9 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "16 + 100 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "86 + 90 = 0\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "34 + 86 = 0\n",
            "------------\n",
            "iters:800\n",
            "Loss:2.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "103 + 55 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:2.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "26 + 99 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:2.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "30 + 121 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "88 + 27 = 0\n",
            "------------\n",
            "iters:1200\n",
            "Loss:2.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "92 + 90 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "79 + 28 = 0\n",
            "------------\n",
            "iters:1400\n",
            "Loss:3.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "95 + 80 = 0\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "3 + 43 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "59 + 84 = 0\n",
            "------------\n",
            "iters:1700\n",
            "Loss:3.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "37 + 89 = 0\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "32 + 61 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "13 + 106 = 0\n",
            "------------\n",
            "iters:2000\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "21 + 64 = 0\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "90 + 60 = 0\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "122 + 27 = 0\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "21 + 126 = 0\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "66 + 118 = 0\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "36 + 25 = 0\n",
            "------------\n",
            "iters:2600\n",
            "Loss:2.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "34 + 26 = 0\n",
            "------------\n",
            "iters:2700\n",
            "Loss:2.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "100 + 23 = 0\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "50 + 6 = 0\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "38 + 53 = 0\n",
            "------------\n",
            "iters:3000\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "53 + 61 = 0\n",
            "------------\n",
            "iters:3100\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "15 + 72 = 0\n",
            "------------\n",
            "iters:3200\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "25 + 44 = 0\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 1 0 0]\n",
            "100 + 120 = 0\n",
            "------------\n",
            "iters:3400\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "23 + 46 = 0\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "109 + 78 = 0\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "7 + 73 = 0\n",
            "------------\n",
            "iters:3700\n",
            "Loss:3.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "127 + 60 = 0\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.5\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "103 + 93 = 4\n",
            "------------\n",
            "iters:3900\n",
            "Loss:2.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "21 + 102 = 0\n",
            "------------\n",
            "iters:4000\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "80 + 64 = 0\n",
            "------------\n",
            "iters:4100\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "103 + 74 = 0\n",
            "------------\n",
            "iters:4200\n",
            "Loss:2.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "34 + 88 = 0\n",
            "------------\n",
            "iters:4300\n",
            "Loss:1.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "28 + 51 = 0\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "74 + 67 = 0\n",
            "------------\n",
            "iters:4500\n",
            "Loss:3.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "63 + 124 = 0\n",
            "------------\n",
            "iters:4600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 0 1 0 0 1]\n",
            "9 + 0 = 0\n",
            "------------\n",
            "iters:4700\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "83 + 35 = 0\n",
            "------------\n",
            "iters:4800\n",
            "Loss:1.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "60 + 26 = 0\n",
            "------------\n",
            "iters:4900\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "5 + 72 = 0\n",
            "------------\n",
            "iters:5000\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "30 + 109 = 0\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.875\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "92 + 53 = 16\n",
            "------------\n",
            "iters:5200\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "62 + 51 = 0\n",
            "------------\n",
            "iters:5300\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "76 + 117 = 0\n",
            "------------\n",
            "iters:5400\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "41 + 77 = 0\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.5\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "103 + 93 = 4\n",
            "------------\n",
            "iters:5600\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "109 + 121 = 0\n",
            "------------\n",
            "iters:5700\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "119 + 105 = 0\n",
            "------------\n",
            "iters:5800\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "53 + 4 = 0\n",
            "------------\n",
            "iters:5900\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "27 + 63 = 0\n",
            "------------\n",
            "iters:6000\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "19 + 75 = 0\n",
            "------------\n",
            "iters:6100\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "105 + 83 = 0\n",
            "------------\n",
            "iters:6200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "91 + 23 = 0\n",
            "------------\n",
            "iters:6300\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "1 + 86 = 0\n",
            "------------\n",
            "iters:6400\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "66 + 127 = 0\n",
            "------------\n",
            "iters:6500\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "47 + 32 = 0\n",
            "------------\n",
            "iters:6600\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "49 + 22 = 0\n",
            "------------\n",
            "iters:6700\n",
            "Loss:1.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "120 + 37 = 0\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "4 + 60 = 0\n",
            "------------\n",
            "iters:6900\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "5 + 41 = 0\n",
            "------------\n",
            "iters:7000\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "108 + 59 = 0\n",
            "------------\n",
            "iters:7100\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "85 + 109 = 0\n",
            "------------\n",
            "iters:7200\n",
            "Loss:2.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "110 + 77 = 0\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "98 + 119 = 0\n",
            "------------\n",
            "iters:7400\n",
            "Loss:2.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "94 + 12 = 0\n",
            "------------\n",
            "iters:7500\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "111 + 3 = 0\n",
            "------------\n",
            "iters:7600\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "29 + 20 = 0\n",
            "------------\n",
            "iters:7700\n",
            "Loss:1.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "91 + 70 = 0\n",
            "------------\n",
            "iters:7800\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "50 + 103 = 0\n",
            "------------\n",
            "iters:7900\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 0 1 0 1]\n",
            "21 + 0 = 0\n",
            "------------\n",
            "iters:8000\n",
            "Loss:1.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "102 + 85 = 0\n",
            "------------\n",
            "iters:8100\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "117 + 47 = 0\n",
            "------------\n",
            "iters:8200\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "44 + 56 = 0\n",
            "------------\n",
            "iters:8300\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "12 + 38 = 0\n",
            "------------\n",
            "iters:8400\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "74 + 116 = 0\n",
            "------------\n",
            "iters:8500\n",
            "Loss:2.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "38 + 73 = 0\n",
            "------------\n",
            "iters:8600\n",
            "Loss:1.875\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "82 + 29 = 0\n",
            "------------\n",
            "iters:8700\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "65 + 50 = 0\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "60 + 111 = 0\n",
            "------------\n",
            "iters:8900\n",
            "Loss:1.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "37 + 111 = 0\n",
            "------------\n",
            "iters:9000\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "67 + 66 = 0\n",
            "------------\n",
            "iters:9100\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "41 + 116 = 0\n",
            "------------\n",
            "iters:9200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "45 + 54 = 0\n",
            "------------\n",
            "iters:9300\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "74 + 2 = 0\n",
            "------------\n",
            "iters:9400\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "47 + 108 = 0\n",
            "------------\n",
            "iters:9500\n",
            "Loss:1.375\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "22 + 86 = 0\n",
            "------------\n",
            "iters:9600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "31 + 53 = 4\n",
            "------------\n",
            "iters:9700\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "123 + 28 = 0\n",
            "------------\n",
            "iters:9800\n",
            "Loss:1.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "13 + 71 = 0\n",
            "------------\n",
            "iters:9900\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "81 + 77 = 0\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "WP_cPm9pM5m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        # delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])       \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * d_tanh(y[:,t])\n",
        "\n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        # delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u7lL-ifjMu7s",
        "outputId": "e646dbac-c87a-4ecf-e942-3e07f6f52a1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:0.8711116582384255\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "126 + 76 = 250\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0382959911644167\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "77 + 81 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.6378200602643025\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "27 + 99 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.399067207615905\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "51 + 30 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.75830298879239\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "52 + 80 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.6728882678466589\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "13 + 52 = 1\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.1485779163984633\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "101 + 50 = 0\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.2530905996668076\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "91 + 6 = 255\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.1370741069638701\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "86 + 126 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9551498635849984\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "74 + 124 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.397977440472401\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "66 + 61 = 1\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8081183952217594\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "81 + 0 = 1\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.9336636933207023\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[1 1 0 1 0 0 1 1]\n",
            "118 + 93 = 3\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.7671074550184732\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "54 + 25 = 255\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7268030877933244\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "1 + 78 = 255\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0293174316345464\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "59 + 82 = 255\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8504832988176142\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "40 + 6 = 2\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.4289961874377715\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "110 + 87 = 255\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.8662977959769935\n",
            "Pred:[0 0 0 1 0 1 1 0]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "21 + 3 = 22\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9078936356169963\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "121 + 4 = 1\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.6830486781392741\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "46 + 85 = 3\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.9191050982567148\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "0 + 103 = 1\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.7443365884178287\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "97 + 77 = 254\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.209987119420865\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "98 + 82 = 0\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.6666705895259077\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "1 + 49 = 48\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.7610768331242983\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "1 + 47 = 0\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.9940804905896676\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "117 + 39 = 254\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.7143537479827677\n",
            "Pred:[1 1 1 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "91 + 65 = 248\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.8539042954011985\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "58 + 81 = 255\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.8171645728629567\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "52 + 122 = 254\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.9000712681504731\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "66 + 99 = 255\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.9273363180331138\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "43 + 100 = 1\n",
            "------------\n",
            "iters:3200\n",
            "Loss:1.014879395769996\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "89 + 7 = 88\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.7977085382015422\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "92 + 0 = 254\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.8363081345938865\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "121 + 93 = 254\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.8760178915359731\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "67 + 95 = 254\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.0238182768192283\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "118 + 105 = 3\n",
            "------------\n",
            "iters:3700\n",
            "Loss:1.519917105645513\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "53 + 122 = 1\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.8201211464520944\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "31 + 8 = 3\n",
            "------------\n",
            "iters:3900\n",
            "Loss:1.2603298992066767\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "83 + 18 = 255\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.9778544390005109\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "93 + 24 = 1\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.8865077187906198\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "4 + 116 = 254\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.630926598131101\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "106 + 68 = 254\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.7475234993454284\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "99 + 82 = 253\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.169692698803625\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "65 + 61 = 64\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.9463694980576072\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "52 + 83 = 1\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.9437333082401355\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "68 + 7 = 1\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.723947876741087\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "21 + 101 = 254\n",
            "------------\n",
            "iters:4800\n",
            "Loss:1.1561307394556188\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "76 + 17 = 1\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.9070615393556052\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "71 + 33 = 252\n",
            "------------\n",
            "iters:5000\n",
            "Loss:1.218953949748411\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "0 + 26 = 254\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.7277285003387455\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "42 + 113 = 3\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.7606880727683148\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "2 + 50 = 0\n",
            "------------\n",
            "iters:5300\n",
            "Loss:1.0926616728611263\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "29 + 102 = 251\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.8708502387311319\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "101 + 9 = 100\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.781906735504439\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "43 + 126 = 249\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.9495215380997439\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "29 + 17 = 254\n",
            "------------\n",
            "iters:5700\n",
            "Loss:1.1844310370901145\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "68 + 23 = 255\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.981757819493288\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "75 + 78 = 253\n",
            "------------\n",
            "iters:5900\n",
            "Loss:1.0800101227617702\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "21 + 115 = 252\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.7819502120038201\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "92 + 82 = 254\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.7340244358107819\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "64 + 90 = 90\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.9666483652820298\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "27 + 65 = 0\n",
            "------------\n",
            "iters:6300\n",
            "Loss:1.1153080666882444\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "98 + 68 = 254\n",
            "------------\n",
            "iters:6400\n",
            "Loss:1.2277400009226616\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "5 + 73 = 254\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.7538679245148482\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "37 + 111 = 252\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.7681674704782935\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "71 + 87 = 254\n",
            "------------\n",
            "iters:6700\n",
            "Loss:1.0987858043069403\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "87 + 86 = 249\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.838878205567196\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "109 + 98 = 3\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.6229326162453181\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "98 + 19 = 253\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.9346808377437521\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "22 + 123 = 253\n",
            "------------\n",
            "iters:7100\n",
            "Loss:1.6555597727509825\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "52 + 4 = 254\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.7377041870746234\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "59 + 24 = 3\n",
            "------------\n",
            "iters:7300\n",
            "Loss:1.4985628504438102\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "62 + 9 = 255\n",
            "------------\n",
            "iters:7400\n",
            "Loss:1.160152387554811\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "53 + 23 = 252\n",
            "------------\n",
            "iters:7500\n",
            "Loss:1.119610293806356\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "22 + 21 = 1\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.7422651949274678\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "114 + 9 = 255\n",
            "------------\n",
            "iters:7700\n",
            "Loss:1.0555232977769053\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "126 + 48 = 0\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.7605540863359431\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 1 1 1 1 0 0 0]\n",
            "121 + 127 = 4\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.9282230792434172\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "115 + 19 = 254\n",
            "------------\n",
            "iters:8000\n",
            "Loss:1.5631991552802291\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "94 + 39 = 253\n",
            "------------\n",
            "iters:8100\n",
            "Loss:1.6660260193128986\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "76 + 12 = 254\n",
            "------------\n",
            "iters:8200\n",
            "Loss:1.2061465254861856\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "76 + 20 = 222\n",
            "------------\n",
            "iters:8300\n",
            "Loss:1.519008254730339\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "5 + 127 = 252\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.9545566741814127\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "82 + 95 = 253\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.9522323911120706\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "43 + 127 = 254\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.7424391172969704\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "123 + 36 = 255\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.9384757372148884\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "76 + 71 = 1\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.9039725029166408\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "64 + 77 = 255\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.7488489043455413\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "69 + 114 = 255\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.6098826894852912\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "5 + 88 = 253\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.8103106036816652\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "34 + 70 = 252\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.6932880340916902\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "45 + 88 = 1\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.7417401043684319\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "111 + 75 = 254\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.605613946353037\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "98 + 23 = 253\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.6214792941650181\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "29 + 76 = 249\n",
            "------------\n",
            "iters:9600\n",
            "Loss:1.2159007925814733\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "25 + 86 = 3\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.6437464515656788\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "21 + 120 = 253\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.9191011835153807\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "27 + 74 = 1\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.8858164712855733\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "36 + 90 = 74\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}