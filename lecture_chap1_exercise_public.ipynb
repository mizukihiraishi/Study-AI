{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture_chap1_exercise_public.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wzT0I8w9AM81",
        "eBw_ZiwDAM85"
      ],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Ht1-DGiJAM7f"
      },
      "cell_type": "markdown",
      "source": [
        "# 演習 Sequence-to-Sequence (Seq2Seq) モデル"
      ]
    },
    {
      "metadata": {
        "id": "lImUIx2SAM7h"
      },
      "cell_type": "markdown",
      "source": [
        "Sequence-to-Sequence (Seq2Seq) モデルは、系列を入力として系列を出力するモデルです。\n",
        "\n",
        "入力系列をRNNで固定長のベクトルに変換(= Encode)し、そのベクトルを用いて系列を出力(= Decode)することから、Encoder-Decoder モデルとも呼ばれます。\n",
        "\n",
        "RNNの代わりにLSTMやGRUでも可能です。\n",
        "\n",
        "機械翻訳のほか、文書要約や対話生成にも使われます。<br>\n",
        "今回は機械翻訳を例にとって解説していきます。"
      ]
    },
    {
      "metadata": {
        "id": "V4sqRdFNGAIN"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "AlrUn0gcNevH",
        "outputId": "8ddf4e80-44e4-4569-f03a-620dc87e0271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "#print(accelerator)\n",
        "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install torch==1.5.0 torchvision==0.6.0\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.5.0\n",
            "  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 752.0 MB 8.9 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.0\n",
            "  Downloading torchvision-0.6.0-cp37-cp37m-manylinux1_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.0) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.5.0 torchvision-0.6.0\n",
            "1.5.0\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "55_hatEGIB3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31e9c2e-d71b-418b-d078-1d2b8d65da79"
      },
      "cell_type": "code",
      "source": [
        "! wget https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
        "! mkdir images data\n",
        "\n",
        "# data取得\n",
        "! wget https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en -P data/\n",
        "! wget https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja -P data/\n",
        "! wget https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en -P data/\n",
        "! wget https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja -P data/\n",
        "! wget https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en -P data/\n",
        "! wget https://www.dropbox.com/s/ak53qirssci6f1j/train.ja -P data/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-03 11:38:13--  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9narw5x4uizmehh/utils.py [following]\n",
            "--2022-01-03 11:38:13--  https://www.dropbox.com/s/raw/9narw5x4uizmehh/utils.py\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucdc134138326977b391a588032f.dl.dropboxusercontent.com/cd/0/inline/BdGxg1YrvRUlQ14I5yv52Df_5ZoNSFJgh0_D-SSzuE6aebsqztil-URXO5Tpb1OvsotSjWJ6ztaXGC09A1G3D84m204aJdnIQU0C-LTJR8UyGo89lN_2GOzphmx4jGXvdMT3HAyrxuQwouZg1G82l7rL/file# [following]\n",
            "--2022-01-03 11:38:13--  https://ucdc134138326977b391a588032f.dl.dropboxusercontent.com/cd/0/inline/BdGxg1YrvRUlQ14I5yv52Df_5ZoNSFJgh0_D-SSzuE6aebsqztil-URXO5Tpb1OvsotSjWJ6ztaXGC09A1G3D84m204aJdnIQU0C-LTJR8UyGo89lN_2GOzphmx4jGXvdMT3HAyrxuQwouZg1G82l7rL/file\n",
            "Resolving ucdc134138326977b391a588032f.dl.dropboxusercontent.com (ucdc134138326977b391a588032f.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to ucdc134138326977b391a588032f.dl.dropboxusercontent.com (ucdc134138326977b391a588032f.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949 [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]     949  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-03 11:38:13 (100 MB/s) - ‘utils.py’ saved [949/949]\n",
            "\n",
            "--2022-01-03 11:38:13--  https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/o4kyc52a8we25wy/dev.en [following]\n",
            "--2022-01-03 11:38:14--  https://www.dropbox.com/s/raw/o4kyc52a8we25wy/dev.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfb80c0d01e23203897b81b81c3.dl.dropboxusercontent.com/cd/0/inline/BdGO28r2KzF_hF-h1bVZngbzTTCBpGpsHy-YxsNFM2c1QGX8QmiK_0k0O4kOYVwVEUCliI6B0pCNpJi7bR8Rn8CYH0vgCRgOD6P7ciFMdiIUD2YRCMjJARoQq-vhja2zBigtI_u2XK7_cKGuVC1V28sF/file# [following]\n",
            "--2022-01-03 11:38:14--  https://ucfb80c0d01e23203897b81b81c3.dl.dropboxusercontent.com/cd/0/inline/BdGO28r2KzF_hF-h1bVZngbzTTCBpGpsHy-YxsNFM2c1QGX8QmiK_0k0O4kOYVwVEUCliI6B0pCNpJi7bR8Rn8CYH0vgCRgOD6P7ciFMdiIUD2YRCMjJARoQq-vhja2zBigtI_u2XK7_cKGuVC1V28sF/file\n",
            "Resolving ucfb80c0d01e23203897b81b81c3.dl.dropboxusercontent.com (ucfb80c0d01e23203897b81b81c3.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to ucfb80c0d01e23203897b81b81c3.dl.dropboxusercontent.com (ucfb80c0d01e23203897b81b81c3.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17054 (17K) [text/plain]\n",
            "Saving to: ‘data/dev.en’\n",
            "\n",
            "dev.en              100%[===================>]  16.65K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-01-03 11:38:14 (1.13 MB/s) - ‘data/dev.en’ saved [17054/17054]\n",
            "\n",
            "--2022-01-03 11:38:14--  https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/kdgskm5hzg6znuc/dev.ja [following]\n",
            "--2022-01-03 11:38:14--  https://www.dropbox.com/s/raw/kdgskm5hzg6znuc/dev.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4a5e3b812c29622cacab8631a6.dl.dropboxusercontent.com/cd/0/inline/BdHJYsrzd_6DZoM32SnHTcRLB9lsFebkoi0fh4TaF4TMo3l2WUUvVadEOVgu1NMe9jrJeikpvW3Wa4h51gN102764VGGJtuIu9U1srxLZXOINLShC4T34B2iM3yBDjezsj3guhZRTv1NIuo51O_R8kiF/file# [following]\n",
            "--2022-01-03 11:38:15--  https://uc4a5e3b812c29622cacab8631a6.dl.dropboxusercontent.com/cd/0/inline/BdHJYsrzd_6DZoM32SnHTcRLB9lsFebkoi0fh4TaF4TMo3l2WUUvVadEOVgu1NMe9jrJeikpvW3Wa4h51gN102764VGGJtuIu9U1srxLZXOINLShC4T34B2iM3yBDjezsj3guhZRTv1NIuo51O_R8kiF/file\n",
            "Resolving uc4a5e3b812c29622cacab8631a6.dl.dropboxusercontent.com (uc4a5e3b812c29622cacab8631a6.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to uc4a5e3b812c29622cacab8631a6.dl.dropboxusercontent.com (uc4a5e3b812c29622cacab8631a6.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27781 (27K) [text/plain]\n",
            "Saving to: ‘data/dev.ja’\n",
            "\n",
            "dev.ja              100%[===================>]  27.13K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-01-03 11:38:15 (1.26 MB/s) - ‘data/dev.ja’ saved [27781/27781]\n",
            "\n",
            "--2022-01-03 11:38:15--  https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/gyyx4gohv9v65uh/test.en [following]\n",
            "--2022-01-03 11:38:15--  https://www.dropbox.com/s/raw/gyyx4gohv9v65uh/test.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2ff96e2ab2b9afda1b56af2bfd.dl.dropboxusercontent.com/cd/0/inline/BdHZzCRbn7LjB4cR3TvYSZo5bSwFn-nysv76WsYknAbCmJRh3aCY_ABPxm07Hjx03uLc2F3i6GI-9qh0DbInzxXCvgNnt4SMvrqBcieXw90B8mBCj6JiHSPVX-Ygs8Vk2Sf2p4WWgxPOWNgntSQxt63z/file# [following]\n",
            "--2022-01-03 11:38:15--  https://uc2ff96e2ab2b9afda1b56af2bfd.dl.dropboxusercontent.com/cd/0/inline/BdHZzCRbn7LjB4cR3TvYSZo5bSwFn-nysv76WsYknAbCmJRh3aCY_ABPxm07Hjx03uLc2F3i6GI-9qh0DbInzxXCvgNnt4SMvrqBcieXw90B8mBCj6JiHSPVX-Ygs8Vk2Sf2p4WWgxPOWNgntSQxt63z/file\n",
            "Resolving uc2ff96e2ab2b9afda1b56af2bfd.dl.dropboxusercontent.com (uc2ff96e2ab2b9afda1b56af2bfd.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc2ff96e2ab2b9afda1b56af2bfd.dl.dropboxusercontent.com (uc2ff96e2ab2b9afda1b56af2bfd.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17301 (17K) [text/plain]\n",
            "Saving to: ‘data/test.en’\n",
            "\n",
            "test.en             100%[===================>]  16.90K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-01-03 11:38:16 (1.13 MB/s) - ‘data/test.en’ saved [17301/17301]\n",
            "\n",
            "--2022-01-03 11:38:16--  https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/hotxwbgoe2n013k/test.ja [following]\n",
            "--2022-01-03 11:38:16--  https://www.dropbox.com/s/raw/hotxwbgoe2n013k/test.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucbca038e844116cb953b883dd65.dl.dropboxusercontent.com/cd/0/inline/BdHA2rRqz6RKioc4nV41MX2_g3aphVxXkzFiUte-kgFTG3kz5XoGaGBeRBtnQn4FeZLybH46KAmLFrcgLE1CK9smuQZfv6Wm9pTxEQ-4X6QmVBMQ-hoXLrl64QTJImFxZfr1-OyAddXiA1ykAyAhCK_v/file# [following]\n",
            "--2022-01-03 11:38:17--  https://ucbca038e844116cb953b883dd65.dl.dropboxusercontent.com/cd/0/inline/BdHA2rRqz6RKioc4nV41MX2_g3aphVxXkzFiUte-kgFTG3kz5XoGaGBeRBtnQn4FeZLybH46KAmLFrcgLE1CK9smuQZfv6Wm9pTxEQ-4X6QmVBMQ-hoXLrl64QTJImFxZfr1-OyAddXiA1ykAyAhCK_v/file\n",
            "Resolving ucbca038e844116cb953b883dd65.dl.dropboxusercontent.com (ucbca038e844116cb953b883dd65.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucbca038e844116cb953b883dd65.dl.dropboxusercontent.com (ucbca038e844116cb953b883dd65.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27793 (27K) [text/plain]\n",
            "Saving to: ‘data/test.ja’\n",
            "\n",
            "test.ja             100%[===================>]  27.14K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-01-03 11:38:17 (408 KB/s) - ‘data/test.ja’ saved [27793/27793]\n",
            "\n",
            "--2022-01-03 11:38:17--  https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/5lsftkmb20ay9e1/train.en [following]\n",
            "--2022-01-03 11:38:18--  https://www.dropbox.com/s/raw/5lsftkmb20ay9e1/train.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc736db450231ccbb7c733c5ebb4.dl.dropboxusercontent.com/cd/0/inline/BdGuaHGp6sBa4ml-BiSP1y2AU7Q8nrbpMnbIZasnXryoY2E4Wf8ZUAFys7SzSLveSpI0G0k3dwvDwqy-m-I4cFWLmWZxQtwYtSdx62dgAz1W2TqHasSEEyvGQRA8fJt0XFuOdzTbKHAybizFhn2CgmtS/file# [following]\n",
            "--2022-01-03 11:38:18--  https://uc736db450231ccbb7c733c5ebb4.dl.dropboxusercontent.com/cd/0/inline/BdGuaHGp6sBa4ml-BiSP1y2AU7Q8nrbpMnbIZasnXryoY2E4Wf8ZUAFys7SzSLveSpI0G0k3dwvDwqy-m-I4cFWLmWZxQtwYtSdx62dgAz1W2TqHasSEEyvGQRA8fJt0XFuOdzTbKHAybizFhn2CgmtS/file\n",
            "Resolving uc736db450231ccbb7c733c5ebb4.dl.dropboxusercontent.com (uc736db450231ccbb7c733c5ebb4.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to uc736db450231ccbb7c733c5ebb4.dl.dropboxusercontent.com (uc736db450231ccbb7c733c5ebb4.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1701356 (1.6M) [text/plain]\n",
            "Saving to: ‘data/train.en’\n",
            "\n",
            "train.en            100%[===================>]   1.62M  3.76MB/s    in 0.4s    \n",
            "\n",
            "2022-01-03 11:38:19 (3.76 MB/s) - ‘data/train.en’ saved [1701356/1701356]\n",
            "\n",
            "--2022-01-03 11:38:19--  https://www.dropbox.com/s/ak53qirssci6f1j/train.ja\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ak53qirssci6f1j/train.ja [following]\n",
            "--2022-01-03 11:38:19--  https://www.dropbox.com/s/raw/ak53qirssci6f1j/train.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc24eef469aec3b663a2c61d2b52.dl.dropboxusercontent.com/cd/0/inline/BdG8n-Eoeal3UyleMbGPof69CCyJ9-Fq3KiCVG9o8hy1e9PQwPccGK1DaG8IZux5AqN0i9-LOIKlPmlQtsOUMShghxmMSo0kkAuSgxtJXGfjo3VcVeOYcyKmZ8wfGj_dFRXEcj3iye_3h2_NHcB5Wll9/file# [following]\n",
            "--2022-01-03 11:38:20--  https://uc24eef469aec3b663a2c61d2b52.dl.dropboxusercontent.com/cd/0/inline/BdG8n-Eoeal3UyleMbGPof69CCyJ9-Fq3KiCVG9o8hy1e9PQwPccGK1DaG8IZux5AqN0i9-LOIKlPmlQtsOUMShghxmMSo0kkAuSgxtJXGfjo3VcVeOYcyKmZ8wfGj_dFRXEcj3iye_3h2_NHcB5Wll9/file\n",
            "Resolving uc24eef469aec3b663a2c61d2b52.dl.dropboxusercontent.com (uc24eef469aec3b663a2c61d2b52.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc24eef469aec3b663a2c61d2b52.dl.dropboxusercontent.com (uc24eef469aec3b663a2c61d2b52.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2784447 (2.7M) [text/plain]\n",
            "Saving to: ‘data/train.ja’\n",
            "\n",
            "train.ja            100%[===================>]   2.66M  15.8MB/s    in 0.2s    \n",
            "\n",
            "2022-01-03 11:38:20 (15.8 MB/s) - ‘data/train.ja’ saved [2784447/2784447]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xp5QEw8CICiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088cea05-f37b-4e2d-b4a1-6ebbb218a688"
      },
      "cell_type": "code",
      "source": [
        "! ls data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.en\tdev.ja\ttest.en  test.ja  train.en  train.ja\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_HauAB3uAM7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a5dd7b-1ea7-4bf0-e2a5-240f5bff001b"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from nltk import bleu_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "from utils import Vocab\n",
        "\n",
        "# デバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random_state = 42\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pAmQOdx0AM7o"
      },
      "cell_type": "markdown",
      "source": [
        "# 1.データセットの準備\n",
        "英語-日本語の対訳コーパスである、Tanaka Corpus ( http://www.edrdg.org/wiki/index.php/Tanaka_Corpus )を使います。<br>\n",
        "今回はそのうちの一部分を取り出したsmall_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods ( https://github.com/odashi/small_parallel_enja )を使用します。\n",
        "\n",
        "train.enとtrain.jaの中身を見てみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "gVxFp2MmAM7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbde42b-defa-4060-9446-1defde1cd048"
      },
      "cell_type": "code",
      "source": [
        "! head -10 data/train.en"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i can 't tell who will arrive first .\n",
            "many animals have been destroyed by men .\n",
            "i 'm in the tennis club .\n",
            "emi looks happy .\n",
            "please bear this fact in mind .\n",
            "she takes care of my children .\n",
            "we want to be international .\n",
            "you ought not to break your promise .\n",
            "when you cross the street , watch out for cars .\n",
            "i have nothing to live for .\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jSgmTKl7AM7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e826f0e9-a688-48b9-91a5-d9dd6596f4de"
      },
      "cell_type": "code",
      "source": [
        "! head -10 ./data/train.ja"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
            "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
            "私 は テニス 部員 で す 。\n",
            "エミ は 幸せ そう に 見え ま す 。\n",
            "この 事実 を 心 に 留め て お い て 下さ い 。\n",
            "彼女 は 私 たち の 世話 を し て くれ る 。\n",
            "私 達 は 国際 人 に な り た い と 思 い ま す 。\n",
            "約束 を 破 る べ き で は あ り ま せ ん 。\n",
            "道路 を 横切 る とき は 車 に 注意 し なさ い 。\n",
            "私 に は 生き 甲斐 が な い 。\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UbgN52WHAM7y"
      },
      "cell_type": "markdown",
      "source": [
        "それぞれの文章が英語-日本語で対応しているのがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "OQhfLZ5lAM7z"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1データの読み込みと単語の分割"
      ]
    },
    {
      "metadata": {
        "id": "coc6DTCUAM71"
      },
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    # テキストファイルからデータを読み込むメソッド\n",
        "    data = []\n",
        "    for line in open(file_path, encoding='utf-8'):\n",
        "        words = line.strip().split()  # スペースで単語を分割\n",
        "        data.append(words)\n",
        "    return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5UMnxsTAM74"
      },
      "cell_type": "code",
      "source": [
        "train_X = load_data('./data/train.en')\n",
        "train_Y = load_data('./data/train.ja')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ryYkPteoAM76"
      },
      "cell_type": "code",
      "source": [
        "# 訓練データと検証データに分割\n",
        "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yB4jwiCAM79"
      },
      "cell_type": "markdown",
      "source": [
        "この時点で入力と教師データは以下のようになっています"
      ]
    },
    {
      "metadata": {
        "id": "0HV1SNLAAM7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd08b4e1-05f3-4a22-9bf6-7abaffd78963"
      },
      "cell_type": "code",
      "source": [
        "print('train data', train_X[0])\n",
        "print('valid data', valid_X[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data ['where', 'shall', 'we', 'eat', 'tonight', '?']\n",
            "valid data ['you', 'may', 'extend', 'your', 'stay', 'in', 'tokyo', '.']\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NeB7llfIAM8E"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2単語辞書の作成\n",
        "データセットに登場する各単語にIDを割り振る"
      ]
    },
    {
      "metadata": {
        "id": "b-OqjDkXAM8F"
      },
      "cell_type": "code",
      "source": [
        "# まず特殊トークンを定義しておく\n",
        "PAD_TOKEN = '<PAD>'  # バッチ処理の際に、短い系列の末尾を埋めるために使う （Padding）\n",
        "BOS_TOKEN = '<S>'  # 系列の始まりを表す （Beggining of sentence）\n",
        "EOS_TOKEN = '</S>'  # 系列の終わりを表す （End of sentence）\n",
        "UNK_TOKEN = '<UNK>'  # 語彙に存在しない単語を表す （Unknown）\n",
        "PAD = 0\n",
        "BOS = 1\n",
        "EOS = 2\n",
        "UNK = 3"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_G7dYnTAM8I"
      },
      "cell_type": "code",
      "source": [
        "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数 再提出現回数に満たない単語はUNKに置き換えられる\n",
        "\n",
        "# 単語をIDに変換する辞書の初期値を設定\n",
        "word2id = {\n",
        "    PAD_TOKEN: PAD,\n",
        "    BOS_TOKEN: BOS,\n",
        "    EOS_TOKEN: EOS,\n",
        "    UNK_TOKEN: UNK,\n",
        "    }\n",
        "\n",
        "# 単語辞書を作成\n",
        "vocab_X = Vocab(word2id=word2id)\n",
        "vocab_Y = Vocab(word2id=word2id)\n",
        "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
        "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xDhdQ4FAM8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa99c44-893e-4325-fb56-af860677962d"
      },
      "cell_type": "code",
      "source": [
        "vocab_size_X = len(vocab_X.id2word)\n",
        "vocab_size_Y = len(vocab_Y.id2word)\n",
        "print('入力言語の語彙数：', vocab_size_X)\n",
        "print('出力言語の語彙数：', vocab_size_Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力言語の語彙数： 3725\n",
            "出力言語の語彙数： 4405\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "P-K_xHBkC5TC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf692757-3b27-49a8-9858-d40b46aed75c"
      },
      "cell_type": "code",
      "source": [
        "vocab_X.id2word"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<PAD>',\n",
              " 1: '<S>',\n",
              " 2: '</S>',\n",
              " 3: '<UNK>',\n",
              " 4: '.',\n",
              " 5: 'the',\n",
              " 6: 'i',\n",
              " 7: 'to',\n",
              " 8: 'you',\n",
              " 9: 'is',\n",
              " 10: 'he',\n",
              " 11: 'a',\n",
              " 12: '?',\n",
              " 13: 'in',\n",
              " 14: 'it',\n",
              " 15: 'of',\n",
              " 16: 'she',\n",
              " 17: 'for',\n",
              " 18: 'my',\n",
              " 19: 'have',\n",
              " 20: 'this',\n",
              " 21: \"'t\",\n",
              " 22: 'was',\n",
              " 23: 'me',\n",
              " 24: ',',\n",
              " 25: 'that',\n",
              " 26: 'at',\n",
              " 27: 'his',\n",
              " 28: 'we',\n",
              " 29: 'do',\n",
              " 30: 'will',\n",
              " 31: 'on',\n",
              " 32: 'her',\n",
              " 33: \"'s\",\n",
              " 34: 'with',\n",
              " 35: 'not',\n",
              " 36: 'your',\n",
              " 37: 'are',\n",
              " 38: 'what',\n",
              " 39: 'be',\n",
              " 40: 'as',\n",
              " 41: 'can',\n",
              " 42: 'him',\n",
              " 43: 'there',\n",
              " 44: 'don',\n",
              " 45: 'has',\n",
              " 46: 'go',\n",
              " 47: 'like',\n",
              " 48: 'up',\n",
              " 49: 'all',\n",
              " 50: 'time',\n",
              " 51: 'out',\n",
              " 52: 'by',\n",
              " 53: 'very',\n",
              " 54: 'come',\n",
              " 55: 'they',\n",
              " 56: 'how',\n",
              " 57: 'from',\n",
              " 58: 'please',\n",
              " 59: 'no',\n",
              " 60: 'and',\n",
              " 61: 'had',\n",
              " 62: 'good',\n",
              " 63: \"'m\",\n",
              " 64: 'am',\n",
              " 65: 'here',\n",
              " 66: 'did',\n",
              " 67: 'get',\n",
              " 68: 'about',\n",
              " 69: 'been',\n",
              " 70: \"'ll\",\n",
              " 71: 'when',\n",
              " 72: 'take',\n",
              " 73: 'see',\n",
              " 74: 'an',\n",
              " 75: 'so',\n",
              " 76: 'work',\n",
              " 77: 'let',\n",
              " 78: 'day',\n",
              " 79: 'know',\n",
              " 80: 'would',\n",
              " 81: 'now',\n",
              " 82: 'went',\n",
              " 83: 'well',\n",
              " 84: 'going',\n",
              " 85: 'father',\n",
              " 86: 'were',\n",
              " 87: 'book',\n",
              " 88: 'if',\n",
              " 89: 'than',\n",
              " 90: 'should',\n",
              " 91: 'one',\n",
              " 92: 'school',\n",
              " 93: 'may',\n",
              " 94: 'last',\n",
              " 95: 'home',\n",
              " 96: 'much',\n",
              " 97: '!',\n",
              " 98: 'want',\n",
              " 99: 'got',\n",
              " 100: 'money',\n",
              " 101: 'make',\n",
              " 102: 'made',\n",
              " 103: 'more',\n",
              " 104: 'long',\n",
              " 105: 'man',\n",
              " 106: 'english',\n",
              " 107: 'any',\n",
              " 108: 'car',\n",
              " 109: 'us',\n",
              " 110: 'tomorrow',\n",
              " 111: 'too',\n",
              " 112: 'help',\n",
              " 113: 'but',\n",
              " 114: 'must',\n",
              " 115: 'room',\n",
              " 116: 'came',\n",
              " 117: 'house',\n",
              " 118: 'our',\n",
              " 119: 'could',\n",
              " 120: 'yesterday',\n",
              " 121: 'way',\n",
              " 122: 'new',\n",
              " 123: 'off',\n",
              " 124: 'mother',\n",
              " 125: 'after',\n",
              " 126: 'back',\n",
              " 127: 'think',\n",
              " 128: 'some',\n",
              " 129: 'better',\n",
              " 130: 'today',\n",
              " 131: 'soon',\n",
              " 132: 'where',\n",
              " 133: 'nothing',\n",
              " 134: 'always',\n",
              " 135: 'before',\n",
              " 136: 'every',\n",
              " 137: 'who',\n",
              " 138: 'late',\n",
              " 139: 'many',\n",
              " 140: 'old',\n",
              " 141: 'put',\n",
              " 142: 'just',\n",
              " 143: 'night',\n",
              " 144: 'look',\n",
              " 145: 'little',\n",
              " 146: 'people',\n",
              " 147: 'two',\n",
              " 148: 'hard',\n",
              " 149: 'down',\n",
              " 150: 'next',\n",
              " 151: 'over',\n",
              " 152: 'give',\n",
              " 153: 'morning',\n",
              " 154: 'tell',\n",
              " 155: 'years',\n",
              " 156: \"'ve\",\n",
              " 157: 'say',\n",
              " 158: 'took',\n",
              " 159: 'said',\n",
              " 160: 'didn',\n",
              " 161: 'once',\n",
              " 162: 'never',\n",
              " 163: 'station',\n",
              " 164: 'does',\n",
              " 165: 'keep',\n",
              " 166: 'speak',\n",
              " 167: 'right',\n",
              " 168: 'train',\n",
              " 169: 'plan',\n",
              " 170: 'into',\n",
              " 171: 'party',\n",
              " 172: 'cannot',\n",
              " 173: 'cold',\n",
              " 174: 'ten',\n",
              " 175: 'walk',\n",
              " 176: 'three',\n",
              " 177: 'boy',\n",
              " 178: 'week',\n",
              " 179: 'read',\n",
              " 180: 'such',\n",
              " 181: 'live',\n",
              " 182: 'rain',\n",
              " 183: 'teacher',\n",
              " 184: \"'d\",\n",
              " 185: 'lot',\n",
              " 186: 'bus',\n",
              " 187: 'left',\n",
              " 188: 'children',\n",
              " 189: 'away',\n",
              " 190: 'tom',\n",
              " 191: 'play',\n",
              " 192: 'call',\n",
              " 193: 'happy',\n",
              " 194: 'leave',\n",
              " 195: 'only',\n",
              " 196: 'kind',\n",
              " 197: 'name',\n",
              " 198: 'accident',\n",
              " 199: 'mind',\n",
              " 200: 'letter',\n",
              " 201: 'true',\n",
              " 202: 'again',\n",
              " 203: 'why',\n",
              " 204: 'news',\n",
              " 205: 'life',\n",
              " 206: 'watch',\n",
              " 207: 'feel',\n",
              " 208: 'brother',\n",
              " 209: 'dog',\n",
              " 210: 'job',\n",
              " 211: 'study',\n",
              " 212: 'best',\n",
              " 213: 'problem',\n",
              " 214: 'anything',\n",
              " 215: 'other',\n",
              " 216: 'saw',\n",
              " 217: 'days',\n",
              " 218: 'use',\n",
              " 219: 'something',\n",
              " 220: 'books',\n",
              " 221: 'japan',\n",
              " 222: 'year',\n",
              " 223: 'friends',\n",
              " 224: 'or',\n",
              " 225: 'far',\n",
              " 226: 'meeting',\n",
              " 227: 'gave',\n",
              " 228: 'early',\n",
              " 229: 'often',\n",
              " 230: 'friend',\n",
              " 231: 'lost',\n",
              " 232: 'story',\n",
              " 233: 'looked',\n",
              " 234: 'great',\n",
              " 235: 'yourself',\n",
              " 236: 'stay',\n",
              " 237: 'matter',\n",
              " 238: 'first',\n",
              " 239: 'busy',\n",
              " 240: 'found',\n",
              " 241: 'doctor',\n",
              " 242: 'used',\n",
              " 243: 'answer',\n",
              " 244: 'met',\n",
              " 245: 'seems',\n",
              " 246: 'need',\n",
              " 247: 'care',\n",
              " 248: 'enough',\n",
              " 249: 'them',\n",
              " 250: 'beautiful',\n",
              " 251: 'sister',\n",
              " 252: 'thing',\n",
              " 253: 'tennis',\n",
              " 254: 'while',\n",
              " 255: 'girl',\n",
              " 256: 'business',\n",
              " 257: 'child',\n",
              " 258: 'which',\n",
              " 259: 'heard',\n",
              " 260: 'young',\n",
              " 261: 'doesn',\n",
              " 262: 'five',\n",
              " 263: \"'re\",\n",
              " 264: 'their',\n",
              " 265: 'told',\n",
              " 266: 'hear',\n",
              " 267: 'door',\n",
              " 268: 'students',\n",
              " 269: 'question',\n",
              " 270: 'these',\n",
              " 271: 'finished',\n",
              " 272: 'write',\n",
              " 273: 'son',\n",
              " 274: 'own',\n",
              " 275: 'without',\n",
              " 276: 'looking',\n",
              " 277: 'bad',\n",
              " 278: 'wrong',\n",
              " 279: 'bed',\n",
              " 280: 'looks',\n",
              " 281: 'another',\n",
              " 282: 'river',\n",
              " 283: 'since',\n",
              " 284: 'tokyo',\n",
              " 285: 'tired',\n",
              " 286: 'weather',\n",
              " 287: 'family',\n",
              " 288: 'homework',\n",
              " 289: 'water',\n",
              " 290: 'eat',\n",
              " 291: 'comes',\n",
              " 292: 'few',\n",
              " 293: 'idea',\n",
              " 294: 'coming',\n",
              " 295: 'bought',\n",
              " 296: 'health',\n",
              " 297: 'quite',\n",
              " 298: 'everything',\n",
              " 299: 'run',\n",
              " 300: 'along',\n",
              " 301: 'love',\n",
              " 302: 'town',\n",
              " 303: 'asked',\n",
              " 304: 'sure',\n",
              " 305: 'difficult',\n",
              " 306: 'seen',\n",
              " 307: 'hand',\n",
              " 308: 'turn',\n",
              " 309: 'parents',\n",
              " 310: 'being',\n",
              " 311: 'hours',\n",
              " 312: 'talk',\n",
              " 313: 'called',\n",
              " 314: 'nice',\n",
              " 315: 'music',\n",
              " 316: 'turned',\n",
              " 317: 'easy',\n",
              " 318: 'place',\n",
              " 319: 'yet',\n",
              " 320: 'getting',\n",
              " 321: 'shall',\n",
              " 322: 'hope',\n",
              " 323: 'still',\n",
              " 324: 'minutes',\n",
              " 325: 'try',\n",
              " 326: 'done',\n",
              " 327: 'married',\n",
              " 328: 'won',\n",
              " 329: 'because',\n",
              " 330: 'japanese',\n",
              " 331: 'ever',\n",
              " 332: 'reading',\n",
              " 333: 'ran',\n",
              " 334: 'coffee',\n",
              " 335: 'really',\n",
              " 336: 'john',\n",
              " 337: 'open',\n",
              " 338: 'able',\n",
              " 339: 'park',\n",
              " 340: 'success',\n",
              " 341: 'meet',\n",
              " 342: 'arrived',\n",
              " 343: 'ask',\n",
              " 344: 'swim',\n",
              " 345: 'buy',\n",
              " 346: 'believe',\n",
              " 347: 'mary',\n",
              " 348: 'picture',\n",
              " 349: 'examination',\n",
              " 350: 'afraid',\n",
              " 351: 'isn',\n",
              " 352: 'wait',\n",
              " 353: 'wish',\n",
              " 354: 'tv',\n",
              " 355: 'waiting',\n",
              " 356: 'fast',\n",
              " 357: 'word',\n",
              " 358: 'baby',\n",
              " 359: 'dictionary',\n",
              " 360: 'summer',\n",
              " 361: 'kept',\n",
              " 362: 'alone',\n",
              " 363: 'same',\n",
              " 364: 'dinner',\n",
              " 365: 'ago',\n",
              " 366: 'student',\n",
              " 367: 'tonight',\n",
              " 368: 'eyes',\n",
              " 369: 'street',\n",
              " 370: 'start',\n",
              " 371: 'doing',\n",
              " 372: 'gone',\n",
              " 373: 'abroad',\n",
              " 374: 'sorry',\n",
              " 375: 'game',\n",
              " 376: 'show',\n",
              " 377: 'drink',\n",
              " 378: 'class',\n",
              " 379: 'most',\n",
              " 380: 'playing',\n",
              " 381: 'smoking',\n",
              " 382: 'goes',\n",
              " 383: 'food',\n",
              " 384: 'around',\n",
              " 385: 'interesting',\n",
              " 386: 'through',\n",
              " 387: 'things',\n",
              " 388: 'world',\n",
              " 389: 'big',\n",
              " 390: 'ill',\n",
              " 391: 'window',\n",
              " 392: 'sick',\n",
              " 393: 'agree',\n",
              " 394: 'himself',\n",
              " 395: 'lived',\n",
              " 396: 'those',\n",
              " 397: 'afternoon',\n",
              " 398: 'snow',\n",
              " 399: 'find',\n",
              " 400: 'couldn',\n",
              " 401: 'order',\n",
              " 402: 'truth',\n",
              " 403: 'month',\n",
              " 404: 'broke',\n",
              " 405: 'lives',\n",
              " 406: 'set',\n",
              " 407: \"''\",\n",
              " 408: 'table',\n",
              " 409: 'began',\n",
              " 410: 'company',\n",
              " 411: 'angry',\n",
              " 412: 'each',\n",
              " 413: 'country',\n",
              " 414: 'remember',\n",
              " 415: 'end',\n",
              " 416: 'mine',\n",
              " 417: 'everybody',\n",
              " 418: 'advice',\n",
              " 419: 'myself',\n",
              " 420: 'present',\n",
              " 421: 'visit',\n",
              " 422: 'french',\n",
              " 423: 'catch',\n",
              " 424: 'dress',\n",
              " 425: 'less',\n",
              " 426: 'sunday',\n",
              " 427: 'hour',\n",
              " 428: 'free',\n",
              " 429: 'carry',\n",
              " 430: 'happened',\n",
              " 431: 'known',\n",
              " 432: 'stop',\n",
              " 433: 'small',\n",
              " 434: 'uncle',\n",
              " 435: 'face',\n",
              " 436: 'person',\n",
              " 437: 'tall',\n",
              " 438: 'six',\n",
              " 439: 'succeed',\n",
              " 440: 'hot',\n",
              " 441: 'talking',\n",
              " 442: 'fire',\n",
              " 443: 'trouble',\n",
              " 444: 'office',\n",
              " 445: 'hotel',\n",
              " 446: 'opinion',\n",
              " 447: 'thank',\n",
              " 448: 'times',\n",
              " 449: 'then',\n",
              " 450: 'pass',\n",
              " 451: 'evening',\n",
              " 452: 'likes',\n",
              " 453: 'important',\n",
              " 454: 'desk',\n",
              " 455: 'large',\n",
              " 456: 'mistake',\n",
              " 457: 'wife',\n",
              " 458: 'fine',\n",
              " 459: 'mr',\n",
              " 460: 'tried',\n",
              " 461: 'caught',\n",
              " 462: 'sight',\n",
              " 463: 'london',\n",
              " 464: 'until',\n",
              " 465: 'change',\n",
              " 466: 'makes',\n",
              " 467: 'running',\n",
              " 468: 'short',\n",
              " 469: 'lunch',\n",
              " 470: 'baseball',\n",
              " 471: 'tea',\n",
              " 472: 'rich',\n",
              " 473: 'sleep',\n",
              " 474: 'having',\n",
              " 475: 'bicycle',\n",
              " 476: 'o',\n",
              " 477: \"'clock\",\n",
              " 478: 'breakfast',\n",
              " 479: 'bill',\n",
              " 480: 'telephone',\n",
              " 481: 'trip',\n",
              " 482: 'against',\n",
              " 483: 'worked',\n",
              " 484: 'hurry',\n",
              " 485: 'understand',\n",
              " 486: 'phone',\n",
              " 487: 'everyone',\n",
              " 488: 'words',\n",
              " 489: 'city',\n",
              " 490: 'knows',\n",
              " 491: 'america',\n",
              " 492: 'camera',\n",
              " 493: 'account',\n",
              " 494: 'high',\n",
              " 495: 'working',\n",
              " 496: 'forget',\n",
              " 497: 'failed',\n",
              " 498: 'point',\n",
              " 499: 'thought',\n",
              " 500: 'ready',\n",
              " 501: 'poor',\n",
              " 502: 'takes',\n",
              " 503: 'honest',\n",
              " 504: 'born',\n",
              " 505: 'across',\n",
              " 506: 'studying',\n",
              " 507: 'movie',\n",
              " 508: 'piano',\n",
              " 509: 'fail',\n",
              " 510: 'walked',\n",
              " 511: 'fell',\n",
              " 512: 'shoes',\n",
              " 513: 'age',\n",
              " 514: 'box',\n",
              " 515: 'others',\n",
              " 516: 'says',\n",
              " 517: 'full',\n",
              " 518: 'pay',\n",
              " 519: 'road',\n",
              " 520: 'ken',\n",
              " 521: 'learn',\n",
              " 522: 'decided',\n",
              " 523: 'building',\n",
              " 524: 'near',\n",
              " 525: 'haven',\n",
              " 526: 'died',\n",
              " 527: 'stand',\n",
              " 528: 'already',\n",
              " 529: 'fun',\n",
              " 530: 'police',\n",
              " 531: 'hat',\n",
              " 532: 'ought',\n",
              " 533: 'jane',\n",
              " 534: 'cup',\n",
              " 535: 'fish',\n",
              " 536: 'bring',\n",
              " 537: 'even',\n",
              " 538: 'store',\n",
              " 539: 'drive',\n",
              " 540: 'making',\n",
              " 541: 'become',\n",
              " 542: 'speech',\n",
              " 543: 'garden',\n",
              " 544: 'kyoto',\n",
              " 545: 'dream',\n",
              " 546: 'part',\n",
              " 547: 'vacation',\n",
              " 548: 'light',\n",
              " 549: 'strange',\n",
              " 550: 'fact',\n",
              " 551: 'wanted',\n",
              " 552: 'flowers',\n",
              " 553: 'paris',\n",
              " 554: 'war',\n",
              " 555: 'lake',\n",
              " 556: 'traffic',\n",
              " 557: 'longer',\n",
              " 558: 'means',\n",
              " 559: 'surprised',\n",
              " 560: 'daughter',\n",
              " 561: 'under',\n",
              " 562: 'hair',\n",
              " 563: 'wonder',\n",
              " 564: 'wants',\n",
              " 565: 'result',\n",
              " 566: 'mistakes',\n",
              " 567: 'herself',\n",
              " 568: 'illness',\n",
              " 569: 'possible',\n",
              " 570: 'plane',\n",
              " 571: 'dollars',\n",
              " 572: 'speaks',\n",
              " 573: 'birthday',\n",
              " 574: 'york',\n",
              " 575: 'absent',\n",
              " 576: 'glad',\n",
              " 577: 'solve',\n",
              " 578: 'moment',\n",
              " 579: 'bank',\n",
              " 580: 'seeing',\n",
              " 581: 'almost',\n",
              " 582: 'promise',\n",
              " 583: 'someone',\n",
              " 584: 'number',\n",
              " 585: 'airport',\n",
              " 586: 'rather',\n",
              " 587: 'heavy',\n",
              " 588: 'till',\n",
              " 589: 'living',\n",
              " 590: 'tears',\n",
              " 591: 'started',\n",
              " 592: 'library',\n",
              " 593: 'sit',\n",
              " 594: 'cake',\n",
              " 595: 'song',\n",
              " 596: 'medicine',\n",
              " 597: 'later',\n",
              " 598: 'both',\n",
              " 599: 'stayed',\n",
              " 600: 'air',\n",
              " 601: 'lend',\n",
              " 602: 'television',\n",
              " 603: 'exam',\n",
              " 604: 'seven',\n",
              " 605: 'yours',\n",
              " 606: 'raining',\n",
              " 607: 'sense',\n",
              " 608: 'different',\n",
              " 609: 'passed',\n",
              " 610: 'usually',\n",
              " 611: 'became',\n",
              " 612: 'pen',\n",
              " 613: 'reason',\n",
              " 614: 'whether',\n",
              " 615: 'anxious',\n",
              " 616: 'front',\n",
              " 617: 'brought',\n",
              " 618: 'novel',\n",
              " 619: 'certain',\n",
              " 620: 'attend',\n",
              " 621: 'sea',\n",
              " 622: 'nobody',\n",
              " 623: 'head',\n",
              " 624: 'behind',\n",
              " 625: 'case',\n",
              " 626: 'felt',\n",
              " 627: 'sat',\n",
              " 628: 'clear',\n",
              " 629: 'cut',\n",
              " 630: 'cat',\n",
              " 631: 'death',\n",
              " 632: 'watching',\n",
              " 633: 'mean',\n",
              " 634: 'finish',\n",
              " 635: 'future',\n",
              " 636: 'winter',\n",
              " 637: 'enjoyed',\n",
              " 638: 'sun',\n",
              " 639: 'quiet',\n",
              " 640: 'rest',\n",
              " 641: 'tree',\n",
              " 642: 'during',\n",
              " 643: 'gets',\n",
              " 644: 'hospital',\n",
              " 645: 'spring',\n",
              " 646: 'kindness',\n",
              " 647: 'danger',\n",
              " 648: 'heart',\n",
              " 649: 'close',\n",
              " 650: 'visited',\n",
              " 651: 'taking',\n",
              " 652: 'together',\n",
              " 653: 'above',\n",
              " 654: 'stopped',\n",
              " 655: 'happen',\n",
              " 656: 'village',\n",
              " 657: 'swimming',\n",
              " 658: 'proposal',\n",
              " 659: 'clean',\n",
              " 660: 'necessary',\n",
              " 661: 'bag',\n",
              " 662: 'wrote',\n",
              " 663: 'works',\n",
              " 664: 'pretty',\n",
              " 665: 'taken',\n",
              " 666: 'touch',\n",
              " 667: 'radio',\n",
              " 668: 'miss',\n",
              " 669: 'stood',\n",
              " 670: 'chance',\n",
              " 671: 'helped',\n",
              " 672: 'writing',\n",
              " 673: 'careful',\n",
              " 674: 'sometimes',\n",
              " 675: 'expensive',\n",
              " 676: 'seat',\n",
              " 677: 'jim',\n",
              " 678: 'experience',\n",
              " 679: 'secret',\n",
              " 680: 'impossible',\n",
              " 681: 'hands',\n",
              " 682: 'sky',\n",
              " 683: 'played',\n",
              " 684: 'earth',\n",
              " 685: 'boys',\n",
              " 686: 'lie',\n",
              " 687: 'shop',\n",
              " 688: 'forward',\n",
              " 689: 'fool',\n",
              " 690: 'questions',\n",
              " 691: 'address',\n",
              " 692: 'college',\n",
              " 693: 'famous',\n",
              " 694: 'coat',\n",
              " 695: 'send',\n",
              " 696: 'dark',\n",
              " 697: 'dead',\n",
              " 698: 'paper',\n",
              " 699: 'voice',\n",
              " 700: 'travel',\n",
              " 701: 'machine',\n",
              " 702: 'four',\n",
              " 703: 'paid',\n",
              " 704: 'yen',\n",
              " 705: 'clothes',\n",
              " 706: 'easily',\n",
              " 707: 'hold',\n",
              " 708: 'mountain',\n",
              " 709: 'bridge',\n",
              " 710: 'succeeded',\n",
              " 711: 'singer',\n",
              " 712: 'line',\n",
              " 713: 'noise',\n",
              " 714: 'saying',\n",
              " 715: 'studied',\n",
              " 716: 'break',\n",
              " 717: 'arrive',\n",
              " 718: 'computer',\n",
              " 719: 'spoke',\n",
              " 720: 'whole',\n",
              " 721: 'worth',\n",
              " 722: 'men',\n",
              " 723: 'bob',\n",
              " 724: 'team',\n",
              " 725: 'slowly',\n",
              " 726: 'peace',\n",
              " 727: 'eight',\n",
              " 728: 'husband',\n",
              " 729: 'concert',\n",
              " 730: 'smoke',\n",
              " 731: 'american',\n",
              " 732: 'red',\n",
              " 733: 'walking',\n",
              " 734: 'interested',\n",
              " 735: 'blue',\n",
              " 736: 'quickly',\n",
              " 737: 'side',\n",
              " 738: 'rule',\n",
              " 739: 'also',\n",
              " 740: 'subject',\n",
              " 741: 'strong',\n",
              " 742: 'wind',\n",
              " 743: 'ship',\n",
              " 744: 'taxi',\n",
              " 745: 'hardly',\n",
              " 746: 'woman',\n",
              " 747: 'moon',\n",
              " 748: 'girls',\n",
              " 749: 'between',\n",
              " 750: 'pleased',\n",
              " 751: 'failure',\n",
              " 752: 'test',\n",
              " 753: 'white',\n",
              " 754: 'storm',\n",
              " 755: 'several',\n",
              " 756: 'fishing',\n",
              " 757: 'post',\n",
              " 758: \"'\",\n",
              " 759: 'moved',\n",
              " 760: 'price',\n",
              " 761: 'might',\n",
              " 762: 'spent',\n",
              " 763: 'hit',\n",
              " 764: 'eye',\n",
              " 765: 'deal',\n",
              " 766: 'milk',\n",
              " 767: 'either',\n",
              " 768: 'cost',\n",
              " 769: 'its',\n",
              " 770: 'smith',\n",
              " 771: 'keeps',\n",
              " 772: 'enjoy',\n",
              " 773: 'twice',\n",
              " 774: 'cry',\n",
              " 775: 'check',\n",
              " 776: 'glass',\n",
              " 777: 'purpose',\n",
              " 778: 'half',\n",
              " 779: 'held',\n",
              " 780: 'bit',\n",
              " 781: 'asleep',\n",
              " 782: 'view',\n",
              " 783: 'closed',\n",
              " 784: 'foreign',\n",
              " 785: 'finally',\n",
              " 786: 'report',\n",
              " 787: 'osaka',\n",
              " 788: 'pain',\n",
              " 789: 'policeman',\n",
              " 790: 'doubt',\n",
              " 791: 'speaking',\n",
              " 792: 'win',\n",
              " 793: 'carried',\n",
              " 794: 'given',\n",
              " 795: 'upon',\n",
              " 796: 'blame',\n",
              " 797: 'killed',\n",
              " 798: 'hurt',\n",
              " 799: 'changed',\n",
              " 800: 'broken',\n",
              " 801: 'sing',\n",
              " 802: 'anybody',\n",
              " 803: 'crying',\n",
              " 804: 'university',\n",
              " 805: 'prevented',\n",
              " 806: 'taller',\n",
              " 807: 'sad',\n",
              " 808: 'anyone',\n",
              " 809: 'satisfied',\n",
              " 810: 'sent',\n",
              " 811: 'england',\n",
              " 812: 'popular',\n",
              " 813: 'cars',\n",
              " 814: 'listen',\n",
              " 815: 'driving',\n",
              " 816: 'staying',\n",
              " 817: 'invited',\n",
              " 818: 'waited',\n",
              " 819: 'cook',\n",
              " 820: 'animals',\n",
              " 821: 'beauty',\n",
              " 822: 'ahead',\n",
              " 823: 'language',\n",
              " 824: 'proud',\n",
              " 825: 'hill',\n",
              " 826: 'thinking',\n",
              " 827: 'suddenly',\n",
              " 828: 'president',\n",
              " 829: 'recently',\n",
              " 830: 'shopping',\n",
              " 831: 'movies',\n",
              " 832: 'due',\n",
              " 833: 'eating',\n",
              " 834: 'ability',\n",
              " 835: 'umbrella',\n",
              " 836: 'worry',\n",
              " 837: 'brown',\n",
              " 838: 'laughed',\n",
              " 839: 'newspaper',\n",
              " 840: 'public',\n",
              " 841: 'among',\n",
              " 842: 'leaving',\n",
              " 843: 'cooking',\n",
              " 844: 'leaves',\n",
              " 845: 'stolen',\n",
              " 846: 'die',\n",
              " 847: 'begin',\n",
              " 848: 'fall',\n",
              " 849: 'built',\n",
              " 850: 'wall',\n",
              " 851: 'singing',\n",
              " 852: 'return',\n",
              " 853: 'accustomed',\n",
              " 854: 'afford',\n",
              " 855: 'listening',\n",
              " 856: 'pick',\n",
              " 857: 'favor',\n",
              " 858: 'concerned',\n",
              " 859: 'ticket',\n",
              " 860: 'wasn',\n",
              " 861: 'trees',\n",
              " 862: 'earlier',\n",
              " 863: 'written',\n",
              " 864: 'joke',\n",
              " 865: 'missed',\n",
              " 866: 'ride',\n",
              " 867: 'sound',\n",
              " 868: 'marry',\n",
              " 869: 'floor',\n",
              " 870: 'promised',\n",
              " 871: 'flower',\n",
              " 872: 'none',\n",
              " 873: 'drop',\n",
              " 874: 'telling',\n",
              " 875: 'history',\n",
              " 876: 'pleasant',\n",
              " 877: 'expected',\n",
              " 878: 'older',\n",
              " 879: 'advised',\n",
              " 880: 'else',\n",
              " 881: 'harder',\n",
              " 882: 'loves',\n",
              " 883: 'mail',\n",
              " 884: 'beyond',\n",
              " 885: 'math',\n",
              " 886: 'tony',\n",
              " 887: 'birds',\n",
              " 888: 'laugh',\n",
              " 889: 'pale',\n",
              " 890: 'whatever',\n",
              " 891: 'aren',\n",
              " 892: 'pictures',\n",
              " 893: 'crowd',\n",
              " 894: 'boat',\n",
              " 895: 'borrow',\n",
              " 896: 'knowledge',\n",
              " 897: 'feeling',\n",
              " 898: 'owe',\n",
              " 899: 'enter',\n",
              " 900: 'warm',\n",
              " 901: 'sleeping',\n",
              " 902: 'runs',\n",
              " 903: 'thirty',\n",
              " 904: 'alive',\n",
              " 905: 'wash',\n",
              " 906: 'dangerous',\n",
              " 907: 'key',\n",
              " 908: 'younger',\n",
              " 909: 'usual',\n",
              " 910: 'whose',\n",
              " 911: 'holiday',\n",
              " 912: 'noon',\n",
              " 913: 'rules',\n",
              " 914: 'fond',\n",
              " 915: 'shower',\n",
              " 916: 'top',\n",
              " 917: 'horse',\n",
              " 918: 'studies',\n",
              " 919: 'anywhere',\n",
              " 920: 'clock',\n",
              " 921: 'offer',\n",
              " 922: 'though',\n",
              " 923: 'mouth',\n",
              " 924: 'prefer',\n",
              " 925: 'showed',\n",
              " 926: 'healthy',\n",
              " 927: 'information',\n",
              " 928: 'boss',\n",
              " 929: 'rained',\n",
              " 930: 'happiness',\n",
              " 931: 'arm',\n",
              " 932: 'knew',\n",
              " 933: 'foot',\n",
              " 934: 'needs',\n",
              " 935: 'wonderful',\n",
              " 936: 'familiar',\n",
              " 937: 'expect',\n",
              " 938: 'seemed',\n",
              " 939: 'efforts',\n",
              " 940: 'fever',\n",
              " 941: 'returned',\n",
              " 942: 'golf',\n",
              " 943: 'oh',\n",
              " 944: 'sports',\n",
              " 945: 'baggage',\n",
              " 946: 'childhood',\n",
              " 947: 'excuse',\n",
              " 948: 'rains',\n",
              " 949: 'hurried',\n",
              " 950: 'seem',\n",
              " 951: 'outside',\n",
              " 952: 'pencil',\n",
              " 953: 'cross',\n",
              " 954: 'move',\n",
              " 955: 'skiing',\n",
              " 956: 'piece',\n",
              " 957: 'meals',\n",
              " 958: 'standing',\n",
              " 959: 'past',\n",
              " 960: 'join',\n",
              " 961: 'responsible',\n",
              " 962: 'talked',\n",
              " 963: 'duty',\n",
              " 964: 'invite',\n",
              " 965: 'carefully',\n",
              " 966: 'clever',\n",
              " 967: 'date',\n",
              " 968: 'explanation',\n",
              " 969: 'least',\n",
              " 970: 'i.',\n",
              " 971: 'likely',\n",
              " 972: 'somebody',\n",
              " 973: 'carelessness',\n",
              " 974: 'problems',\n",
              " 975: 'suppose',\n",
              " 976: 'yes',\n",
              " 977: 'answered',\n",
              " 978: 'supper',\n",
              " 979: 'eaten',\n",
              " 980: 'rumor',\n",
              " 981: 'loved',\n",
              " 982: 'sooner',\n",
              " 983: 'appears',\n",
              " 984: 'regret',\n",
              " 985: 'forgot',\n",
              " 986: 'scolded',\n",
              " 987: 'notice',\n",
              " 988: 'reached',\n",
              " 989: 'rely',\n",
              " 990: 'importance',\n",
              " 991: 'guess',\n",
              " 992: 'beginning',\n",
              " 993: 'minute',\n",
              " 994: 'france',\n",
              " 995: 'picnic',\n",
              " 996: 'nine',\n",
              " 997: 'twenty',\n",
              " 998: 'terrible',\n",
              " 999: 'wake',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "NsoRIue9AM8P"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.テンソルへの変換"
      ]
    },
    {
      "metadata": {
        "id": "HsCajwO2AM8Q"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 IDへの変換\n",
        "まずはモデルが文章を認識できるように、文章を単語IDのリストに変換します"
      ]
    },
    {
      "metadata": {
        "id": "gm6qa0fNAM8R"
      },
      "cell_type": "code",
      "source": [
        "def sentence_to_ids(vocab, sentence):\n",
        "    # 単語(str)のリストをID(int)のリストに変換する関数\n",
        "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
        "    ids += [EOS]  # EOSを加える\n",
        "    return ids"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lk0B0VR_AM8T"
      },
      "cell_type": "code",
      "source": [
        "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
        "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
        "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
        "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4pEMlCxAM8X"
      },
      "cell_type": "markdown",
      "source": [
        "この時点で入力と教師データは以下のようになっている"
      ]
    },
    {
      "metadata": {
        "id": "D6OKuYgwAM8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3986ac45-0a19-4fb9-c41c-265a7919abcf"
      },
      "cell_type": "code",
      "source": [
        "print('train data', train_X[0])\n",
        "print('valid data', valid_X[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data [132, 321, 28, 290, 367, 12, 2]\n",
            "valid data [8, 93, 3532, 36, 236, 13, 284, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_DlWrRnQAM8f"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 DataLoaderの定義\n",
        "データセットからバッチを取得するデータローダーを定義します\n",
        "- この際、長さの異なる複数の系列をバッチで並列に扱えるように、短い系列の末尾を特定のシンボル（`<PAD>`など）でパディングし、バッチ内の系列の長さを最長のものに合わせる\n",
        "- (batch_size, max_length)のサイズの行列を得るが、実際にモデルを学習させるときには、バッチをまたいで各時刻ごとに進めていくので、転置して(max_length, batch_size)の形に変える<br>（batch_first=Trueのオプションを使う場合は不要）"
      ]
    },
    {
      "metadata": {
        "id": "YtmFgYLqAM8h"
      },
      "cell_type": "code",
      "source": [
        "def pad_seq(seq, max_length):\n",
        "    # 系列(seq)が指定の文長(max_length)になるように末尾をパディングする\n",
        "    res = seq + [PAD for i in range(max_length - len(seq))]\n",
        "    return res    \n",
        "\n",
        "\n",
        "class DataLoader(object):\n",
        "\n",
        "    def __init__(self, X, Y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        :param X: list, 入力言語の文章（単語IDのリスト）のリスト\n",
        "        :param Y: list, 出力言語の文章（単語IDのリスト）のリスト\n",
        "        :param batch_size: int, バッチサイズ\n",
        "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
        "        \"\"\"\n",
        "        self.data = list(zip(X, Y))\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.start_index = 0\n",
        "        \n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        if self.shuffle:  # サンプルの順番をシャッフルする\n",
        "            self.data = shuffle(self.data, random_state=random_state)\n",
        "        self.start_index = 0  # ポインタの位置を初期化する\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # ポインタが最後まで到達したら初期化する\n",
        "        if self.start_index >= len(self.data):\n",
        "            self.reset()\n",
        "            raise StopIteration()\n",
        "\n",
        "        # バッチを取得\n",
        "        seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
        "        # 入力系列seqs_Xの文章の長さ順（降順）に系列ペアをソートする\n",
        "        seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n",
        "        seqs_X, seqs_Y = zip(*seq_pairs)\n",
        "        # 短い系列の末尾をパディングする\n",
        "        lengths_X = [len(s) for s in seqs_X]  # 後述のEncoderのpack_padded_sequenceでも用いる\n",
        "        lengths_Y = [len(s) for s in seqs_Y]\n",
        "        max_length_X = max(lengths_X)\n",
        "        max_length_Y = max(lengths_Y)\n",
        "        padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n",
        "        padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n",
        "        # tensorに変換し、転置する\n",
        "        batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0, 1)\n",
        "        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n",
        "\n",
        "        # ポインタを更新する\n",
        "        self.start_index += self.batch_size\n",
        "\n",
        "        return batch_X, batch_Y, lengths_X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-37frCXrAM8k"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.モデルの構築\n",
        "EncoderとDecoderのRNNを定義します。"
      ]
    },
    {
      "metadata": {
        "id": "1X3oRjArAM8l"
      },
      "cell_type": "markdown",
      "source": [
        "### 導入：PackedSequence"
      ]
    },
    {
      "metadata": {
        "id": "lRmj-EdbAM8m"
      },
      "cell_type": "markdown",
      "source": [
        "PyTorchのRNNでは、可変長の系列のバッチを効率よく計算できるように系列を表現する`PackedSequence`というクラスを用いることができます。\n",
        "\n",
        "入力バッチのテンソルをこの`PackedSequence`のインスタンスに変換してからRNNに入力することで、パディング部分の計算を省略することができるため、効率的な計算が可能になります。\n",
        "\n",
        "`PackedSequence`を作成するには、まず、系列長の異なるバッチに対してパディングを行なってください。\n",
        "\n",
        "ここで、パディングを行う前に各サンプルの系列長(`lengths`)を保存しておきます。"
      ]
    },
    {
      "metadata": {
        "id": "yWAV3W89AM8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac5a85b-0bf2-4605-80e9-19f3a9c4928c"
      },
      "cell_type": "code",
      "source": [
        "# 系列長がそれぞれ4,3,2の3つのサンプルからなるバッチを作成\n",
        "batch = [[1,2,3,4], [5,6,7], [8,9]]\n",
        "lengths = [len(sample) for sample in batch]\n",
        "print('各サンプルの系列長:', lengths)\n",
        "print()\n",
        "\n",
        "# 最大系列長に合うように各サンプルをpadding\n",
        "_max_length = max(lengths)\n",
        "padded = torch.tensor([pad_seq(sample, _max_length) for sample in batch])\n",
        "print('paddingされたテンソル:\\n', padded)\n",
        "padded = padded.transpose(0,1) # (max_length, batch_size)に転置\n",
        "print('padding & 転置されたテンソル:\\n', padded)\n",
        "print('padding & 転置されたテンソルのサイズ:\\n', padded.size())\n",
        "print()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "各サンプルの系列長: [4, 3, 2]\n",
            "\n",
            "paddingされたテンソル:\n",
            " tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 0],\n",
            "        [8, 9, 0, 0]])\n",
            "padding & 転置されたテンソル:\n",
            " tensor([[1, 5, 8],\n",
            "        [2, 6, 9],\n",
            "        [3, 7, 0],\n",
            "        [4, 0, 0]])\n",
            "padding & 転置されたテンソルのサイズ:\n",
            " torch.Size([4, 3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GTAq1q8mAM8q"
      },
      "cell_type": "markdown",
      "source": [
        "次に、パディングを行ったテンソル(`padded`)と各サンプルの元々の系列長(`lengths`)を`torch.nn.utils.rnn.pack_padded_sequence`という関数に与えると、\n",
        "`data`と`batch_sizes`という要素を持った`PackedSequence`のインスタンス(`packed`)が作成できます。\n",
        "- `data`: テンソルの`PAD`以外の値のみを保有するベクトル\n",
        "- `batch_sizes`: 各時刻で計算が必要な(=`PAD`に到達していない)バッチの数を表すベクトル"
      ]
    },
    {
      "metadata": {
        "id": "FtRm7uqIAM8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb564ec-1bd4-4389-f099-4c48ef92904c"
      },
      "cell_type": "code",
      "source": [
        "# PackedSequenceに変換（テンソルをRNNに入力する前に適用する）\n",
        "packed = pack_padded_sequence(padded, lengths=lengths) # 各サンプルの系列長も与える\n",
        "print('PackedSequenceのインスタンス:\\n', packed) # テンソルのPAD以外の値(data)と各時刻で計算が必要な(=PADに到達していない)バッチの数(batch_sizes)を有するインスタンス\n",
        "print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequenceのインスタンス:\n",
            " PackedSequence(data=tensor([1, 5, 8, 2, 6, 9, 3, 7, 4]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iYKaiMZDAM8w"
      },
      "cell_type": "markdown",
      "source": [
        "こうして得られた`PackedSequence`のインスタンスをRNNに入力します。（ここでは省略）\n",
        "\n",
        "RNNから出力されたテンソルは`PackedSeauence`のインスタンスのままなので、後段の計算につなぐために`torch.nn.utils.rnn.pad_packed_sequence`の関数によって通常のテンソルに戻します。"
      ]
    },
    {
      "metadata": {
        "id": "F7BBaiVzAM8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8447919d-a780-4829-a86c-b5ebf9fe1e02"
      },
      "cell_type": "code",
      "source": [
        "# PackedSequenceのインスタンスをRNNに入力する（ここでは省略）\n",
        "output = packed\n",
        "\n",
        "# テンソルに戻す(RNNの出力に対して適用する)\n",
        "output, _length = pad_packed_sequence(output)  # PADを含む元のテンソルと各サンプルの系列長を返す\n",
        "print('PADを含む元のテンソル:\\n', output)\n",
        "print('各サンプルの系列長:', _length)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PADを含む元のテンソル:\n",
            " tensor([[1, 5, 8],\n",
            "        [2, 6, 9],\n",
            "        [3, 7, 0],\n",
            "        [4, 0, 0]])\n",
            "各サンプルの系列長: tensor([4, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wzT0I8w9AM81"
      },
      "cell_type": "markdown",
      "source": [
        "### Encoder\n",
        "今回はEncoder側でバッチを処理する際に、`pack_padded_sequence`関数によってtensorを`PackedSequence`に変換し、処理を終えた後に`pad_packed_sequence`関数によってtensorに戻すという処理を行います。"
      ]
    },
    {
      "metadata": {
        "id": "NdY2WGwMAM82"
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        \"\"\"\n",
        "        :param input_size: int, 入力言語の語彙数\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, seqs, input_lengths, hidden=None):\n",
        "        \"\"\"\n",
        "        :param seqs: tensor, 入力のバッチ, size=(max_length, batch_size)\n",
        "        :param input_lengths: 入力のバッチの各サンプルの文長\n",
        "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
        "        :return output: tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n",
        "        :return hidden: tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        emb = self.embedding(seqs) # seqsはパディング済み\n",
        "        packed = pack_padded_sequence(emb, input_lengths) # PackedSequenceオブジェクトに変換\n",
        "        output, hidden = self.gru(packed, hidden)\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        return output, hidden"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBw_ZiwDAM85"
      },
      "cell_type": "markdown",
      "source": [
        "### Decoder\n",
        "今回はDecoder側ではパディング等行わないので、通常のtensorのままRNNに入力して問題ありません。"
      ]
    },
    {
      "metadata": {
        "id": "UjKk_-9_AM86"
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        :param output_size: int, 出力言語の語彙数\n",
        "        :param dropout: float, ドロップアウト率\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, seqs, hidden):\n",
        "        \"\"\"\n",
        "        :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n",
        "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
        "        :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n",
        "        :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        emb = self.embedding(seqs)\n",
        "        output, hidden = self.gru(emb, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tf64KCf2AM88"
      },
      "cell_type": "markdown",
      "source": [
        "## EncoderDecoder\n",
        "上で定義したEncoderとDecoderを用いた、一連の処理をまとめるEncoderDecoderのクラスを定義します。\n",
        "\n",
        "ここで、Decoder側の処理で注意する点があります。\n",
        "\n",
        "RNNでは、時刻$t$の出力を時刻$t+1$の入力とすることができるが、この方法でDecoderを学習させると連鎖的に誤差が大きくなっていき、学習が不安定になったり収束が遅くなったりする問題が発生します。\n",
        "\n",
        "\n",
        "この問題への対策として**Teacher Forcing**というテクニックがあります。\n",
        "これは、訓練時にはDecoder側の入力に、ターゲット系列（参照訳）をそのまま使うというものです。\n",
        "これにより学習が安定し、収束が早くなるというメリットがありますが、逆に評価時は前の時刻にDecoderが生成したものが使われるため、学習時と分布が異なってしまうというデメリットもあります。\n",
        "\n",
        "\n",
        "Teacher Forcingの拡張として、ターゲット系列を入力とするか生成された結果を入力とするかを確率的にサンプリングする**Scheduled Sampling**という手法があります。\n",
        "\n",
        "ここではScheduled Samplingを採用し、一定の確率に基づいてターゲット系列を入力とするか生成された結果を入力とするかを切り替えられるようにクラスを定義しておきます。"
      ]
    },
    {
      "metadata": {
        "id": "OB9Nlcd9AM89"
      },
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"EncoderとDecoderの処理をまとめる\"\"\"\n",
        "    def __init__(self, input_size, output_size, hidden_size):\n",
        "        \"\"\"\n",
        "        :param input_size: int, 入力言語の語彙数\n",
        "        :param output_size: int, 出力言語の語彙数\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        \"\"\"\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size)\n",
        "        self.decoder = Decoder(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n",
        "        \"\"\"\n",
        "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
        "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
        "        :param max_length: int, Decoderの最大文長\n",
        "        :param batch_Y: tensor, Decoderで用いるターゲット系列\n",
        "        :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n",
        "        :return decoder_outputs: tensor, Decoderの出力, \n",
        "            size=(max_length, batch_size, self.decoder.output_size)\n",
        "        \"\"\"\n",
        "        # encoderに系列を入力（複数時刻をまとめて処理）\n",
        "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
        "        \n",
        "        _batch_size = batch_X.size(1)\n",
        "\n",
        "        # decoderの入力と隠れ層の初期状態を定義\n",
        "        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device) # 最初の入力にはBOSを使用する\n",
        "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "        decoder_hidden = encoder_hidden  # Encoderの最終隠れ状態を取得\n",
        "\n",
        "        # decoderの出力のホルダーを定義\n",
        "        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device) # max_length分の固定長\n",
        "\n",
        "        # 各時刻ごとに処理\n",
        "        for t in range(max_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            decoder_outputs[t] = decoder_output\n",
        "            # 次の時刻のdecoderの入力を決定\n",
        "            if use_teacher_forcing and batch_Y is not None:  # teacher forceの場合、ターゲット系列を用いる\n",
        "                decoder_input = batch_Y[t].unsqueeze(0)\n",
        "            else:  # teacher forceでない場合、自身の出力を用いる\n",
        "                decoder_input = decoder_output.max(-1)[1]\n",
        "                \n",
        "        return decoder_outputs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBTFmbwLAM9A"
      },
      "cell_type": "markdown",
      "source": [
        "# 4.訓練\n",
        "### 4.1 損失関数の定義\n",
        "基本的にはクロスエントロピーを損失関数として用いますが、パディングを行うと短い系列の末尾には`<PAD>`トークンが入るため、この部分の損失を計算しないように、マスクをかけます。"
      ]
    },
    {
      "metadata": {
        "id": "Kt-r-nxJAM9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1af6f4-7d91-4185-8216-a9b338e93199"
      },
      "cell_type": "code",
      "source": [
        "mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD) # PADを無視する\n",
        "def masked_cross_entropy(logits, target):\n",
        "    logits_flat = logits.view(-1, logits.size(-1)) # (max_seq_len * batch_size, output_size)\n",
        "    target_flat = target.view(-1) # (max_seq_len * batch_size, 1)\n",
        "    return mce(logits_flat, target_flat)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GgQZl0GvAM9E"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2学習"
      ]
    },
    {
      "metadata": {
        "id": "qurGD8IsAM9F"
      },
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの設定\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "lr = 1e-3  # 学習率\n",
        "teacher_forcing_rate = 0.2  # Teacher Forcingを行う確率\n",
        "ckpt_path = 'model.pth'  # 学習済みのモデルを保存するパス\n",
        "\n",
        "model_args = {\n",
        "    'input_size': vocab_size_X,\n",
        "    'output_size': vocab_size_Y,\n",
        "    'hidden_size': 256,\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xNxWJGPAM9I"
      },
      "cell_type": "code",
      "source": [
        "# データローダを定義\n",
        "train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# モデルとOptimizerを定義\n",
        "model = EncoderDecoder(**model_args).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_67wGmARAM9L"
      },
      "cell_type": "markdown",
      "source": [
        "実際に損失関数を計算する関数を定義します。"
      ]
    },
    {
      "metadata": {
        "id": "Adggq9xOAM9L"
      },
      "cell_type": "code",
      "source": [
        "def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n",
        "    # 損失を計算する関数\n",
        "    model.train(is_train)  # train/evalモードの切替え\n",
        "    \n",
        "    # 一定確率でTeacher Forcingを行う\n",
        "    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n",
        "    max_length = batch_Y.size(0)\n",
        "    # 推論\n",
        "    pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n",
        "    \n",
        "    # 損失関数を計算\n",
        "    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
        "    \n",
        "    if is_train:  # 訓練時はパラメータを更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
        "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
        "\n",
        "    return loss.item(), batch_Y, pred"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHJXFnLpAM9O"
      },
      "cell_type": "markdown",
      "source": [
        "ここで、Loss以外に、学習の進捗を確認するためにモデルの性能を評価する指標として、BLEUを計算します。\n",
        "\n",
        "BLEUは機械翻訳の分野において最も一般的な自動評価基準の一つで、予め用意した複数の参照訳と、機械翻訳モデルが出力した訳のn-gramのマッチ率に基づく指標です。\n",
        "\n",
        "NLTK (Natural Language Tool Kit) という自然言語処理で用いられるライブラリを用いて簡単に計算することができます。"
      ]
    },
    {
      "metadata": {
        "id": "ImK-xzAWAM9P"
      },
      "cell_type": "code",
      "source": [
        "def calc_bleu(refs, hyps):\n",
        "    \"\"\"\n",
        "    BLEUスコアを計算する関数\n",
        "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
        "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： ['I', 'have', 'a', 'pen'])\n",
        "    :return: float, BLEUスコア(0~100)\n",
        "    \"\"\"\n",
        "    refs = [[ref[:ref.index(EOS)]] for ref in refs] # EOSは評価しないで良いので切り捨てる, refsのほうは複数なのでlistが一個多くかかっている\n",
        "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
        "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inYRxu8aAM9T"
      },
      "cell_type": "markdown",
      "source": [
        "それではモデルの訓練を行います。"
      ]
    },
    {
      "metadata": {
        "id": "bz-Dx5p6AM9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227f0168-300c-499b-822b-85b64d50127e"
      },
      "cell_type": "code",
      "source": [
        "# 訓練\n",
        "best_valid_bleu = 0.\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_loss = 0.\n",
        "    train_refs = []\n",
        "    train_hyps = []\n",
        "    valid_loss = 0.\n",
        "    valid_refs = []\n",
        "    valid_hyps = []\n",
        "    # train\n",
        "    for batch in train_dataloader:\n",
        "        batch_X, batch_Y, lengths_X = batch\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_X, batch_Y, lengths_X, model, optimizer, \n",
        "            is_train=True\n",
        "            )\n",
        "        train_loss += loss\n",
        "        train_refs += gold\n",
        "        train_hyps += pred\n",
        "    # valid\n",
        "    for batch in valid_dataloader:\n",
        "        batch_X, batch_Y, lengths_X = batch\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_X, batch_Y, lengths_X, model, \n",
        "            is_train=False\n",
        "            )\n",
        "        valid_loss += loss\n",
        "        valid_refs += gold\n",
        "        valid_hyps += pred\n",
        "    # 損失をサンプル数で割って正規化\n",
        "    train_loss = np.sum(train_loss) / len(train_dataloader.data)\n",
        "    valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n",
        "    # BLEUを計算\n",
        "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
        "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
        "\n",
        "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
        "    if valid_bleu > best_valid_bleu:\n",
        "        ckpt = model.state_dict()\n",
        "        torch.save(ckpt, ckpt_path)\n",
        "        best_valid_bleu = valid_bleu\n",
        "\n",
        "    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
        "            epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n",
        "        \n",
        "    print('-'*80)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss: 52.10  train_bleu: 3.60  valid_loss: 48.78  valid_bleu: 4.50\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2: train_loss: 44.82  train_bleu: 7.21  valid_loss: 44.78  valid_bleu: 6.88\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3: train_loss: 40.12  train_bleu: 11.23  valid_loss: 42.39  valid_bleu: 10.70\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4: train_loss: 37.15  train_bleu: 14.32  valid_loss: 41.04  valid_bleu: 11.69\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5: train_loss: 34.86  train_bleu: 16.94  valid_loss: 40.15  valid_bleu: 12.68\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6: train_loss: 33.23  train_bleu: 18.76  valid_loss: 39.89  valid_bleu: 14.18\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7: train_loss: 32.20  train_bleu: 19.92  valid_loss: 39.67  valid_bleu: 13.96\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8: train_loss: 30.38  train_bleu: 22.52  valid_loss: 40.29  valid_bleu: 17.46\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9: train_loss: 29.15  train_bleu: 24.43  valid_loss: 40.39  valid_bleu: 15.27\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10: train_loss: 28.07  train_bleu: 26.10  valid_loss: 40.14  valid_bleu: 15.62\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Y3tlT8z9SCoF"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdgBkAlkAM9V"
      },
      "cell_type": "markdown",
      "source": [
        "# 5.評価"
      ]
    },
    {
      "metadata": {
        "id": "ze8jkchYAM9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b21d2e5-6716-4f65-e75d-ab2b65f64473"
      },
      "cell_type": "code",
      "source": [
        "# 学習済みモデルの読み込み\n",
        "ckpt = torch.load(ckpt_path) # cpuで処理する場合はmap_locationで指定する必要があります。\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "YyKW9WY6AM9Y"
      },
      "cell_type": "code",
      "source": [
        "def ids_to_sentence(vocab, ids):\n",
        "    # IDのリストを単語のリストに変換する\n",
        "    return [vocab.id2word[_id] for _id in ids]\n",
        "\n",
        "def trim_eos(ids):\n",
        "    # IDのリストからEOS以降の単語を除外する\n",
        "    if EOS in ids:\n",
        "        return ids[:ids.index(EOS)]\n",
        "    else:\n",
        "        return ids"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7qCpnSpAM9b"
      },
      "cell_type": "code",
      "source": [
        "# テストデータの読み込み\n",
        "test_X = load_data('./data/dev.en')\n",
        "test_Y = load_data('./data/dev.ja')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41hLJdkNAM9d"
      },
      "cell_type": "code",
      "source": [
        "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
        "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IFK0JzSYAM9m"
      },
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYfjq3shAM9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3069895c-dfd3-4658-f819-ee479ecae116"
      },
      "cell_type": "code",
      "source": [
        "# 生成\n",
        "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
        "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
        "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
        "print('src: {}'.format(sentence_X))\n",
        "print('tgt: {}'.format(sentence_Y))\n",
        "\n",
        "output = model(batch_X, lengths_X, max_length=20)\n",
        "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
        "output_sentence_without_trim = ' '.join(ids_to_sentence(vocab_Y, output))\n",
        "print('out: {}'.format(output_sentence))\n",
        "print('without trim: {}'.format(output_sentence_without_trim))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 を し なさ い 。\n",
            "without trim: 自分 の 仕事 を し なさ い 。 </S> </S> </S> </S> </S> </S> </S> </S> </S> </S> </S> </S>\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "atSEiLMHAM93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305e9aad-868f-48ab-d86a-7b5c67fbdb3a"
      },
      "cell_type": "code",
      "source": [
        "# BLEUの計算\n",
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n",
        "refs_list = []\n",
        "hyp_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_X, batch_Y, lengths_X = batch\n",
        "    pred_Y = model(batch_X, lengths_X, max_length=20)\n",
        "    pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "    refs = batch_Y.view(-1).data.cpu().tolist()\n",
        "    refs_list.append(refs)\n",
        "    hyp_list.append(pred)\n",
        "bleu = calc_bleu(refs_list, hyp_list)\n",
        "print(bleu)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.28627994478108\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "B1UDdsNvruEi"
      },
      "cell_type": "markdown",
      "source": [
        "### Beam Search\n",
        "テストデータに対して新たな文を生成する際、これまでは各時刻で最も確率の高い単語を正解として採用し、次のステップでの入力として使っていました。\n",
        "ただ、本当にやりたいのは、文全体の尤度が最も高くなるような文を生成することです。そのため、ただ近視眼的に確率の高い単語を採用していくより、もう少し大局的に評価していく必要があります。\n",
        "\n",
        "Beam Searchでは、各時刻において一定の数$K$のそれまでのスコア(対数尤度など)の高い文を保持しながら選択を行っていきます。  \n",
        "\n",
        "\n",
        "図はSlack上のものを参照してください。"
      ]
    },
    {
      "metadata": {
        "id": "2vFRiqFwtKsZ"
      },
      "cell_type": "code",
      "source": [
        "class BeamEncoderDecoder(EncoderDecoder):\n",
        "    \"\"\"\n",
        "    Beam Searchでdecodeを行うためのクラス\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, hidden_size, beam_size=4):\n",
        "        \"\"\"\n",
        "        :param input_size: int, 入力言語の語彙数\n",
        "        :param output_size: int, 出力言語の語彙数\n",
        "        :param hidden_size: int, 隠れ層のユニット数\n",
        "        :param beam_size: int, ビーム数\n",
        "        \"\"\"\n",
        "        super(BeamEncoderDecoder, self).__init__(input_size, output_size, hidden_size)\n",
        "        self.beam_size = beam_size\n",
        "\n",
        "    def forward(self, batch_X, lengths_X, max_length):\n",
        "        \"\"\"\n",
        "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
        "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
        "        :param max_length: int, Decoderの最大文長\n",
        "        :return decoder_outputs: list, 各ビームのDecoderの出力\n",
        "        :return finished_scores: list of float, 各ビームのスコア\n",
        "        \"\"\"\n",
        "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
        "\n",
        "        # decoderの入力と隠れ層の初期状態を定義\n",
        "        decoder_input = torch.tensor([BOS] * self.beam_size, dtype=torch.long, device=device)\n",
        "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # beam_sizeの数だけrepeatする\n",
        "        decoder_input = decoder_input.expand(1, beam_size)\n",
        "        decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n",
        "\n",
        "        k = beam_size\n",
        "        finished_beams = []\n",
        "        finished_scores = []\n",
        "        prev_probs = torch.zeros(beam_size, 1, dtype=torch.float, device=device)  # 前の時刻の各ビームの対数尤度を保持しておく\n",
        "        output_size = self.decoder.output_size\n",
        "\n",
        "        # 各時刻ごとに処理\n",
        "        for t in range(max_length):\n",
        "            # decoder_input: (1, k)\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input[-1:], decoder_hidden)\n",
        "            # decoder_output: (1, k, output_size)\n",
        "            # decoder_hidden: (1, k, hidden_size)\n",
        "            decoder_output_t = decoder_output[-1]  # (k, output_size)\n",
        "            log_probs = prev_probs + F.log_softmax(decoder_output_t, dim=-1)  # (k, output_size)\n",
        "            scores = log_probs  # 対数尤度をスコアとする\n",
        "\n",
        "            # スコアの高いビームとその単語を取得\n",
        "            flat_scores = scores.view(-1)  # (k*output_size,)\n",
        "            if t == 0:\n",
        "                flat_scores = flat_scores[:output_size]  # t=0のときは後半の同じ値の繰り返しを除外\n",
        "            top_vs, top_is = flat_scores.data.topk(k)\n",
        "            beam_indices = top_is / output_size  # (k,)\n",
        "            word_indices = top_is % output_size  # (k,)\n",
        "            \n",
        "            # ビームを更新する\n",
        "            _next_beam_indices = []\n",
        "            _next_word_indices = []\n",
        "            for b, w in zip(beam_indices, word_indices):\n",
        "                if w.item() == EOS:  # EOSに到達した場合はそのビームは更新して終了\n",
        "                    k -= 1\n",
        "                    beam = torch.cat([decoder_input.t()[b], w.view(1,)])  # (t+2,)\n",
        "                    score = scores[b, w].item()\n",
        "                    finished_beams.append(beam)\n",
        "                    finished_scores.append(score)\n",
        "                else:   # それ以外の場合はビームを更新\n",
        "                    _next_beam_indices.append(b)\n",
        "                    _next_word_indices.append(w)\n",
        "            if k == 0:\n",
        "                break\n",
        "\n",
        "            # tensorｎに変換\n",
        "            next_beam_indices = torch.tensor(_next_beam_indices, device=device)\n",
        "            next_word_indices = torch.tensor(_next_word_indices, device=device)\n",
        "\n",
        "            # 次の時刻のDecoderの入力を更新\n",
        "            decoder_input = torch.index_select(\n",
        "                decoder_input, dim=-1, index=next_beam_indices)\n",
        "            decoder_input = torch.cat(\n",
        "                [decoder_input, next_word_indices.unsqueeze(0)], dim=0)\n",
        "    \n",
        "            # 次の時刻のDecoderの隠れ層を更新\n",
        "            decoder_hidden = torch.index_select(\n",
        "                decoder_hidden, dim=1, index=next_beam_indices)\n",
        "\n",
        "            # 各ビームの対数尤度を更新\n",
        "            flat_probs = log_probs.view(-1)  # (k*output_size,)\n",
        "            next_indices = (next_beam_indices + 1) * next_word_indices\n",
        "            prev_probs = torch.index_select(\n",
        "                flat_probs, dim=0, index=next_indices).unsqueeze(1)  # (k, 1)\n",
        "\n",
        "        # すべてのビームが完了したらデータを整形\n",
        "        decoder_outputs = [[idx.item() for idx in beam[1:-1]] for beam in finished_beams]\n",
        "        \n",
        "        return decoder_outputs, finished_scores"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DIZ9NHXHttCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5b958f-f85f-4899-ceb9-5119716e4d20"
      },
      "cell_type": "code",
      "source": [
        "# 学習済みモデルの読み込み\n",
        "beam_size = 3\n",
        "beam_model = BeamEncoderDecoder(**model_args, beam_size=beam_size).to(device)\n",
        "beam_model.load_state_dict(ckpt)\n",
        "beam_model.eval()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BeamEncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
              "    (gru): GRU(256, 256)\n",
              "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "KzsI_6bBtwGc"
      },
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSr_wwtbtxKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d71bd21-ac56-482c-b194-a3175fbd9e3e"
      },
      "cell_type": "code",
      "source": [
        "# 生成\n",
        "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
        "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
        "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
        "print('src: {}'.format(sentence_X))\n",
        "print('tgt: {}'.format(sentence_Y))\n",
        "\n",
        "# 普通のdecode\n",
        "output = model(batch_X, lengths_X, max_length=20)\n",
        "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
        "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
        "print('out: {}'.format(output_sentence))\n",
        "\n",
        "# beam decode\n",
        "outputs, scores = beam_model(batch_X, lengths_X, max_length=20)\n",
        "# scoreの良い順にソート\n",
        "outputs, scores = zip(*sorted(zip(outputs, scores), key=lambda x: -x[1]))\n",
        "for o, output in enumerate(outputs):\n",
        "   output_sentence = ' '.join(ids_to_sentence(vocab_Y, output))\n",
        "   print('out{}: {}'.format(o+1, output_sentence))    "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: show your own business .\n",
            "tgt: 自分 の 事 を しろ 。\n",
            "out: 自分 の 仕事 を し なさ い 。\n",
            "out1: 自分 の 仕事 を 。\n",
            "out2: 自分 の 仕事 を し 。\n",
            "out3: 自分 の 仕事 を し なさ い 。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "roOpX8nAAM95"
      },
      "cell_type": "markdown",
      "source": [
        "# 参考文献\n",
        "- [Practical PyTorch: Translation with a Sequence to Sequence Network and Attention](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb)\n",
        "- [Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py)\n",
        "- [Encoder\\-decoderモデルとTeacher Forcing，Scheduled Sampling，Professor Forcing](http://satopirka.com/2018/02/encoder-decoder%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8teacher-forcingscheduled-samplingprofessor-forcing/)\n",
        "- [Sequence\\-to\\-Sequence Learning as Beam\\-Search Optimization](https://arxiv.org/abs/1606.02960)"
      ]
    }
  ]
}